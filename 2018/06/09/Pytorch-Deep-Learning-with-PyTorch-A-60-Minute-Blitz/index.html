<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Deep Learning with PyTorch:A 60 Minute Blitz   一、PyTorch 是什么它是一个基于Python的科学计算包，目标用户有两类：  为了使用GPU来替代numpy。 一个深度学习援救平台：提供最大的灵活性和速度。  开始张量（Tensors)张量类似于Numpy的ndarrays，不同之处在于张量可以使用GPU来加快计算。   from __futur">
<meta name="keywords" content="Pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning with PyTorch(60 Minute)">
<meta property="og:url" content="https://xiaoxiaoaurora.github.io/2018/06/09/Pytorch-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/index.html">
<meta property="og:site_name" content="XiaoXiao">
<meta property="og:description" content="Deep Learning with PyTorch:A 60 Minute Blitz   一、PyTorch 是什么它是一个基于Python的科学计算包，目标用户有两类：  为了使用GPU来替代numpy。 一个深度学习援救平台：提供最大的灵活性和速度。  开始张量（Tensors)张量类似于Numpy的ndarrays，不同之处在于张量可以使用GPU来加快计算。   from __futur">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://i.loli.net/2018/06/15/5b2318dedffb5.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/15/5b231997cbfdf.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/15/5b231afe51e77.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/15/5b23228844307.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/15/5b232499d1256.jpg">
<meta property="og:image" content="https://pytorch.org/tutorials/_images/mnist.png">
<meta property="og:image" content="https://i.loli.net/2018/06/15/5b2382a02805a.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/20/5b29b0d07aa34.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/20/5b29b37ee3361.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/21/5b2b1073be2a2.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/22/5b2cb85890b77.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/24/5b2f2cc535de0.jpg">
<meta property="og:image" content="https://i.loli.net/2018/06/22/5b2cb7c7eab0b.jpg">
<meta property="og:image" content="https://pytorch.org/tutorials/_images/cifar10.png">
<meta property="og:updated_time" content="2019-04-02T06:53:27.106Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Learning with PyTorch(60 Minute)">
<meta name="twitter:description" content="Deep Learning with PyTorch:A 60 Minute Blitz   一、PyTorch 是什么它是一个基于Python的科学计算包，目标用户有两类：  为了使用GPU来替代numpy。 一个深度学习援救平台：提供最大的灵活性和速度。  开始张量（Tensors)张量类似于Numpy的ndarrays，不同之处在于张量可以使用GPU来加快计算。   from __futur">
<meta name="twitter:image" content="https://i.loli.net/2018/06/15/5b2318dedffb5.jpg">



  <link rel="alternate" href="/atom.xml" title="XiaoXiao" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://xiaoxiaoaurora.github.io/2018/06/09/Pytorch-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Deep Learning with PyTorch(60 Minute) | XiaoXiao</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/xiaoxiaoAurora" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">XiaoXiao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-top">

    
    
    
      
    

    

    <a href="/top/" rel="section"><i class="menu-item-icon fa fa-fw fa-signal"></i> <br>top</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-search">

    
    
    
      
    

    

    <a href="/search/" rel="section"><i class="menu-item-icon fa fa-fw fa-search"></i> <br>搜索</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://xiaoxiaoaurora.github.io/2018/06/09/Pytorch-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xiao">
      <meta itemprop="description" content="怕什么真理无穷，进一寸有进一寸的欢喜。">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XiaoXiao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Deep Learning with PyTorch(60 Minute)

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-06-09 09:04:57" itemprop="dateCreated datePublished" datetime="2018-06-09T09:04:57+08:00">2018-06-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-02 14:53:27" itemprop="dateModified" datetime="2019-04-02T14:53:27+08:00">2019-04-02</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch，Tutorials/" itemprop="url" rel="index"><span itemprop="name">Pytorch，Tutorials</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数"></span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长"></span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Deep-Learning-with-PyTorch-A-60-Minute-Blitz"><a href="#Deep-Learning-with-PyTorch-A-60-Minute-Blitz" class="headerlink" title="Deep Learning with PyTorch:A 60 Minute Blitz  "></a>Deep Learning with PyTorch:A 60 Minute Blitz  </h1><hr>
<h1 id="一、PyTorch-是什么"><a href="#一、PyTorch-是什么" class="headerlink" title="一、PyTorch 是什么"></a>一、PyTorch 是什么</h1><p>它是一个基于Python的科学计算包，目标用户有两类：</p>
<ul>
<li>为了使用GPU来替代numpy。</li>
<li>一个深度学习援救平台：提供最大的灵活性和速度。</li>
</ul>
<h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><h3 id="张量（Tensors"><a href="#张量（Tensors" class="headerlink" title="张量（Tensors)"></a>张量（Tensors)</h3><p>张量类似于Numpy的ndarrays，不同之处在于张量可以使用GPU来加快计算。  </p>
<pre><code>from __future__ import print_function
import torch  
</code></pre><p>构建一个未初始化的5*3的矩阵：  </p>
<pre><code>x = torch.empty(5, 3)
print(x)  
</code></pre><p>构建一个随机初始化的矩阵：  </p>
<pre><code>x = torch.rand(5, 3)
print(x)  
</code></pre><p>构建一个以零填充且数据类型为long的矩阵：  </p>
<pre><code>x = torch.zeros(5, 3, dtype=torch.long)  
print(x)  
</code></pre><p>直接从数据构造张量：</p>
<p>x = torch.tensor([5.5, 3])<br>print(x)  </p>
<p>也可以根据现有张量创建张量。这些方法将重用输入张量的属性，例如dtype，除非用户提供了新的值：  </p>
<pre><code>x = x.new_ones(5, 3, dtype=torch.double)   #new_* methods 获取大小 
print(x)  

x = torch.randn_like(x, dtype=torch.float)   # 重写dtype
print(x)             # 结果具有相同的大小
</code></pre><p>获取张量大小：  </p>
<pre><code>print(x.size())
</code></pre><p>注意：torch.Size实际上是一个元组，所以它支持所有的元组操作。  </p>
<h3 id="操作（Operations）"><a href="#操作（Operations）" class="headerlink" title="操作（Operations）"></a>操作（Operations）</h3><p>张量上的操作有多重语法形式，下面我们一加法为例进行讲解。  </p>
<p><strong>加法：语法1</strong>  </p>
<pre><code>print(&quot;x: &quot;, x)
y = torch.rand(5, 3)
print(x + y)  
</code></pre><p><strong>加法：语法2</strong>  </p>
<pre><code>print(&quot;x: &quot;, x)
print(torch.add(x, y))   
</code></pre><p><strong>加法：提供输出张量作为参数</strong>   </p>
<pre><code>result = torch.empty(5, 3)
torch.add(x, y, out=result)
print(result)
</code></pre><p><strong>加法: in-place</strong>  </p>
<pre><code>#adds x to y
y.add_(x)
print(y)  
</code></pre><p>注意：任何使张量在原位发生变异的操作都是用<em>， 例如: x.copy</em>(y), x.t_(),都将会改变x。</p>
<p>可以任意使用标准Numpy-like索引：</p>
<pre><code>print(x)
print(x[:, 1])  
print(x[1, :])
print(x[2, 4])  
</code></pre><p><strong>调整大小(Resizing)：如果您想调整大小/重塑张量，可以使用torch.view</strong>  </p>
<pre><code>x = torch.randn(4, 4)
y = x.view(16)
z = x.view(-1, 8)
print(x.size(), y.size(), z.size())  
</code></pre><p>如果有一个单元张量(a one element tensor)，请使用.item（）将该值作为Python数字来获取  </p>
<pre><code>x = torch.rand(1)
print(x)
print(x.item())  
</code></pre><p><a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener">这里</a>描述了100+张量操作，包括转置，索引，切片，数学运算，线性代数，随机数等。  </p>
<h2 id="NumPy-Bridge"><a href="#NumPy-Bridge" class="headerlink" title="NumPy Bridge"></a>NumPy Bridge</h2><p>把一个torch张量转换为numpy数组或者反过来都是很简单的。</p>
<p>Torch张量和numpy数组将共享潜在的内存，改变其中一个也将改变另一个。  </p>
<p>将Torch张量转换成一个NumPy数组 ：</p>
<pre><code>&gt;&gt;&gt; a = torch.ones(5)
&gt;&gt;&gt; print(a)
Out: tensor([ 1.,  1.,  1.,  1.,  1.])

&gt;&gt;&gt; b = a.numpy()
&gt;&gt;&gt; print(b)  
Out: [1. 1. 1. 1. 1.]  
</code></pre><p>numpy数组的值如何在改变？</p>
<pre><code>a.add_(1)
print(a)
print(b)
</code></pre><p>把NumPy数组转换成Torch张量：<br>看看改变numpy数组如何自动改变torch张量。</p>
<pre><code>import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
np.add(a, 1, out=a)
print(a)
print(b)  
</code></pre><p>所有在CPU上的张量，除了字符张量，都支持在numpy之间转换。</p>
<h2 id="CUDA-张量"><a href="#CUDA-张量" class="headerlink" title="CUDA 张量"></a>CUDA 张量</h2><p>使用  <strong>.to</strong>  函数可以将张量移动到GPU上。  </p>
<pre><code># let us run this cell only if CUDA is available
# We will use ``torch.device`` objects to move tensors in and out of GPU
if torch.cuda.is_available():
    device = torch.device(&quot;cuda&quot;)  # a CUDA device object
    y = torch.ones_like(x, device=device)
    x = x.to(device)
    z = x + y
    print(z)
    print(z.to(&quot;cpu&quot;, torch.double))  
</code></pre><p>Out:  </p>
<blockquote>
<p>tensor([ 0.5921], device=’cuda:0’)<br>tensor([ 0.5921], dtype=torch.float64)  </p>
</blockquote>
<h1 id="Autograd-自动求导（automatic-differentiation）"><a href="#Autograd-自动求导（automatic-differentiation）" class="headerlink" title="Autograd: 自动求导（automatic differentiation）"></a>Autograd: 自动求导（automatic differentiation）</h1><p>PyTorch中所有神经网络的核心是autograd包。我们首先简单介绍一下这个包,然后训练我们的第一个神经网络。  </p>
<p>autograd包为张量上的所有操作提供了自动求导.它是一个运行时定义的框架,这意味着反向传播是根据你的代码如何运行来定义,并且每次迭代可以不同.</p>
<p>接下来我们用一些简单的示例来看这个包。  </p>
<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p><strong>torch.Tensor是包的核心类，如果将其属性requires_grad设置为true,它开始跟踪它上面的所有操作。</strong> 当完成计算时可以调用.backward()并自动计算所有的梯度。<strong>该张量的梯度被计算放入搭配到.grad属性中</strong>。<br>阻止跟踪历史的张量，可以通过调用.detch()将其从计算历史记录中分离出来，并防止跟踪将来的计算。<br>为了防止跟踪历史记录（和使用内存），您还可以在 with torch.no_grad（）包装代码块。这在评估模型时特别有用，因为该模型可能具有requires_grad = True的可训练参数，但我们不需要梯度。  </p>
<p><strong>对自动求导的实现还有一个非常重要的类,即函数(Function)</strong>    </p>
<p><strong>张量（Tensor）和函数(Function)是相互联系的,并形成一个非循环图来构建一个完整的计算过程.每个变量有一个.grad_fn属性,它指向创建该变量的一个Function(用户自己创建的变量除外,它的grad_fn属性为None)。</strong>  </p>
<p>如果你想计算导数,可以在一个张量上调用.backward().如果一个Tensor是一个标量(它只有一个元素值),你不必给backward()指定任何的参数,但是该Variable有多个值,你需要指定一个和该张量相同形状的的gradient参数(查看API发现实际为gradients参数)。  </p>
<pre><code>import torch  

# 创建一个张量，饼设置reuqires_grad=True来跟踪计算过程
x = torch.ones(2, 2, reuqires_grad=True)
print(x)

Out:
 tensor([[ 1.,  1.],
        [ 1.,  1.]])  
</code></pre><p>在张量上执行操作:  </p>
<pre><code>y = x + 2  
print(y)

Out:   
 tensor([[ 3.,  3.],
         [ 3.,  3.]])
</code></pre><p>因为y是通过一个操作创建的,所以它有grad_fn,而x是由用户创建,所以它的grad_fn为None.  </p>
<pre><code>print(y.grad_fn)

Out:  &lt;AddBackward0 object at 0x0000020D2A5CC048&gt;  
</code></pre><p>在张量y上执行更多操作：</p>
<pre><code>z = y * y * 3  
out = z.mean()
print(&quot;z : &quot;, z, &quot;, out: &quot;,  out) 

Out: z :  tensor([[ 27.,  27.],
    [ 27.,  27.]]) , out:  tensor(27.)  
</code></pre><p>.requires_grad_（…）按位（in-place）更改现有张量的requires_grad标志。如果没有给出，输入标志默认为True。  </p>
<pre><code>a = torch.randn(2, 2)
a = ((a * 3) / (a - 0))
print(a.requires_grad)

a.requires_grad_(True)
print(a.requires_grad)  
b = (a * a).sum()
print(b.grad_fn)  
</code></pre><h2 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h2><p>现在我们来执行反向传播,因为out包含一个标量,out.backward()相当于执行out.backward(torch.tensor(1)):  </p>
<pre><code>out.backward()
# 输出out对x的梯度d(out)/d(x):
print(&quot;x.grad: &quot;, x.grad)  
</code></pre><p>输出：<br><img src="https://i.loli.net/2018/06/15/5b2318dedffb5.jpg" alt>  </p>
<p>你应该得到一个值全为4.5的矩阵，我们把out称为张量O。则  </p>
<p><img src="https://i.loli.net/2018/06/15/5b231997cbfdf.jpg" alt>  </p>
<p>我们还可以用自动求导做更多有趣的事：  </p>
<pre><code>x = torch.randn(3, requires_grad=True)
y = x * 2
while y.data.norm() &lt; 1000:
    y = y * 2

print(y)
</code></pre><p>输出：<br><img src="https://i.loli.net/2018/06/15/5b231afe51e77.jpg" alt>  </p>
<p>gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)<br>y.backward(gradients)</p>
<p>print(x.grad)  </p>
<p><img src="https://i.loli.net/2018/06/15/5b23228844307.jpg" alt>  </p>
<p>还可以通过使用torch.no_grad（）包装代码块来停止autograd跟踪在张量上的历史记录，其中require_grad = True：  </p>
<pre><code>print(x.requires_grad)
print((x ** 2).requires_grad)

with torch.no_grad():
    print((x ** 2 ).requires_grad)  
</code></pre><p>输出：  </p>
<p><img src="https://i.loli.net/2018/06/15/5b232499d1256.jpg" alt>  </p>
<p>Documentation of autograd and Function is at <a href="http://pytorch.org/docs/autograd" target="_blank" rel="noopener">http://pytorch.org/docs/autograd</a>  </p>
<h1 id="神经网络（Neural-Networks）"><a href="#神经网络（Neural-Networks）" class="headerlink" title="神经网络（Neural Networks）"></a>神经网络（Neural Networks）</h1><p>可以使用torch.nn包来构建神经网络。<br>我们已知道autograd包,nn包依赖autograd包来定义模型并求导.一个nn.Module包含各个层和一个faward(input)方法,该方法返回output。  </p>
<p>例如,我们来看一下下面这个分类数字图像的网络。<br><img src="https://pytorch.org/tutorials/_images/mnist.png" alt><br>convnet  </p>
<p>这是一个简单的前溃神经网络，它接受一个输入，然后一层接着一层的输入，直到最后得到结果。  </p>
<p>神经网络的典型训练过程如下：  </p>
<ul>
<li>定义神经网络模型。它有一些可学习的参数（或者权重）；</li>
<li>在输入数据集上迭代  </li>
<li>通过神经网络处理输入，主要体现在网络的前向传播;</li>
<li>计算损失（输出结果和正确值的差距大小）  </li>
<li>将梯度反向传播回网络的参数，反向传播求梯度。</li>
<li>根据梯度值更新网络的参数，主要使用如下简单的更新原则： <strong>weight = weight - learning_rate * gradient</strong>  </li>
</ul>
<h2 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h2><p>Let’s define this network:  </p>
<pre><code>import torch 
import torch.nn as nn
import torch.nn.functional as F

Class Net(nn.Module):

    def __init__(self):
        # super就是在子类中调用父类方法时用的。
        super(Net, self).__init__()   # 对继承自父类的属性进行初始化。而且是用父类的初始化方法来初始化继承的属性。也就是说，子类继承了父类的所有属性和方法，父类属性自然会用父类方法来进行初始化。当然，如果初始化的逻辑与父类的不同，不使用父类的方法，自己重新初始化也是可以的。
        # 1 input image channel, 6 output channels, 5*5 square convution
        # kernel
        self.comv1 = nn.Conv2d(1, 6, 5)
        self.comv2 = nn.Conv2d(6, 16, 5)
        # an affine operation: y = Wx + b
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)   

    def forward(self, x):
        # Max pooling over a (2, 2) window
        x = F.max_pool2d(F.relu(self.conv1(x),(2, 2))
        # if the size is a square you can only specify a single number
        x = F.max_pool2d(F.relu(self.conv2(x), 2)
        x = view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x    

    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
        num_features *= s
        return num_features

net = Net()
print(net)        
</code></pre><p>输出：<br><img src="https://i.loli.net/2018/06/15/5b2382a02805a.jpg" alt>  </p>
<p><strong>learn more about the network：</strong><br>在pytorch中只需要定义forward函数即可，backward函数会在使用autograd时自动创建（其中梯度是计算过的）。可以在forward函数中使用Tensor的任何操作。</p>
<p>net.aprameters()会返回模型中可学习的参数。</p>
<pre><code>params = list(net.parameters())
print(&apos;可学习参数的个数：&apos;, len(params))
#print(&quot;可学习的参数：&quot;, params)
print(params[0].size())  # conv1&apos;s的权值
for param in params:
    print(param.size())
</code></pre><p>以上代码段实现将该神经网络的可学习参数都放到params中,并且输出了第一层conv的参数大小.<br>输出：<br><img src="https://i.loli.net/2018/06/20/5b29b0d07aa34.jpg" alt>  </p>
<p>注意：我们来尝试一个32<em>32的随机输入，这个网络（LeNet）期望的输入大小是32</em>32。如果使用的是MINIST数据集来训练这个网络，请把数据集中图片大小调整到32*32。  </p>
<pre><code>input = torch.randn（1，1，32，32）
print(&quot;input: &quot;, input)
out = net(input)
print(&quot;out: &quot;, out)  
</code></pre><p>输出：<br><img src="https://i.loli.net/2018/06/20/5b29b37ee3361.jpg" alt></p>
<p>把所有参数的梯度缓存区清零，然后进行随机梯度的的反向传播。  </p>
<pre><code>net.zero_grad()
out.backward(torch.randn(1, 10))  
</code></pre><p>Note:  </p>
<ul>
<li>torch.nn只支持小批量输入（mini-batches）。整个torch.nn包仅支持作为最小样本量的输入，而不支持单个样本。</li>
<li>例如，nn.Conv2d只接受一个四维张量（nSamples <em> nChannels </em> Height <em> Width），即样本数</em>通道数<em>高度</em>宽度。</li>
<li>如果你有单个样本,只需使用input.unsqueeze(0)来添加一个虚假的批量维度.  </li>
</ul>
<p>在继续之前,我们回顾一下到目前为止见过的所有类。  </p>
<p><strong>回顾:</strong>  </p>
<ul>
<li><strong>torch.Tensor</strong> - 一个支持autograd等操作（比如banckward()）的多维数组，也支持梯度w、r、t等张量。  </li>
<li><strong>nn.Module</strong> - 神经网络模块。封装参数的便捷方式，移动到GPU运行，导出，加载等。</li>
<li><strong>nn.Parameters</strong> - 一种张量，当作为属性赋值给一个模块（Module）时,能被自动注册为一个参数。</li>
<li><strong>autograd.Function</strong> - 实现一个自动求导操作的前向和反向定义,每个张量操作至少创建一个函数节点，该节点连接到创建Tensor并对其历史进行编码的函数。</li>
</ul>
<p>以上内容：</p>
<ul>
<li>定义一个神经网络  </li>
<li>处理输入和调用backward</li>
</ul>
<p>剩下的内容:</p>
<ul>
<li>计算损失值  </li>
<li>更新神经网络的权值</li>
</ul>
<h2 id="损失函数（Loss-Function）"><a href="#损失函数（Loss-Function）" class="headerlink" title="损失函数（Loss Function）"></a>损失函数（Loss Function）</h2><p>一个损失函数接受一对（output， target）作为输入(output为网络的输出,target为实际值),，计算一个值来评估网络的输出和目标值（实际值）相差多少。</p>
<p>在nn包中有几种不同的损失函数。一个简单的损失函数是:nn.MSELoss,它计算的是网络的输出和目标值之间的均方误差。  </p>
<p>例如：   </p>
<pre><code>output = net(input)
target = torch.arrange(1, 11)  # 例如，虚拟目标
target = target.view(1, -1)# 使其与输出(output)形状相同
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)
</code></pre><p>输出：<br><img src="https://i.loli.net/2018/06/21/5b2b1073be2a2.jpg" alt></p>
<p>现在，如果反向跟踪loss,用它的属性.grad_fn，你会的到下面这样的一个计算图：</p>
<p><img src="https://i.loli.net/2018/06/22/5b2cb85890b77.jpg" alt></p>
<p>所以, 当调用loss.backward(),整个图与w、r、t的损失不同,图中所有变量（其requres_grad=True）将拥有.grad变量来累计他们的梯度.</p>
<p>为了说明,我们反向跟踪几步:</p>
<pre><code>print(loss.grad_fn)  # MSELoss
print(loss.grad_fn.next_functions[0][0])  # Linear
print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU
</code></pre><p>输出：  </p>
<p><img src="https://i.loli.net/2018/06/24/5b2f2cc535de0.jpg" alt>  </p>
<h2 id="反向传播（Backprop）"><a href="#反向传播（Backprop）" class="headerlink" title="反向传播（Backprop）"></a>反向传播（Backprop）</h2><p>为了反向传播误差,我们所需做的是调用loss.backward().你需要清除已存在的梯度,否则梯度将被累加到已存在的梯度。  </p>
<p>现在，我们将调用loss.backward(),并查看conv1层的偏置项在反向传播前后的梯度。</p>
<pre><code>net.zero_grad()# zeroes the gradient buffers of all parameters
print(&apos;conv1.bias.grad before backward&apos;)
print(net.conv1.bias.grad) 

loss.backward() 

print(&apos;conv1.bias.grad after backward&apos;)
print(net.conv1.bias.grad)
</code></pre><p>输出：</p>
<p><img src="https://i.loli.net/2018/06/22/5b2cb7c7eab0b.jpg" alt>  </p>
<p>现在我们也知道了如何使用损失函数。</p>
<p>神经网络包包含各种深度神经网络的构建模块和损失函数。完整的文档列表在<a href="http://pytorch.org/docs/nn" target="_blank" rel="noopener">这里</a>。  </p>
<p>接下来是更新权重。</p>
<h2 id="更新权重"><a href="#更新权重" class="headerlink" title="更新权重"></a>更新权重</h2><p>最简单的更新权重的方法是：随机梯度下降（SGD）。  </p>
<pre><code>weight = weight - learning_rate * gradient
</code></pre><p>可以通过以下代码实现梯度更新：</p>
<pre><code>learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)  
</code></pre><p>当使用神经网络时，有几种不同的权重更新方法，例如有SGD,Nesterov-SGD,Adam,RMSProp等。为了能够更好地使用这些方法，Pytorch提供了一个小工具包：torch.optim来实现上述所说的更新方法。使用起来也很简单，代码如下：  </p>
<pre><code>import torch.optim as optim  

# create your optimizer
optimizer = optim.SGD(net.parameters(), lr=0.01)

# in your training loop:
optimizer.zero_grad()    # zero the gradient buffers
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()         # Does the update  
</code></pre><h1 id="训练分类器（Training-a-classifier）"><a href="#训练分类器（Training-a-classifier）" class="headerlink" title="训练分类器（Training a classifier）"></a>训练分类器（Training a classifier）</h1><h2 id="What-about-Data"><a href="#What-about-Data" class="headerlink" title="What about Data?"></a>What about Data?</h2><p>一般来说，在处理图像、文本、音频或者视频数据时可以使用标准的python包把数据加载成一个numpy数组， 然后再把这个数组转换成一个 torch.*Tensor。  </p>
<ul>
<li>对于图像来说，可以使用Pillow、OpenCV等包。  </li>
<li>对于音频来说，可以使用scipy和librosa包。  </li>
<li>对于文本来说，无论是原始的Python还是基于Cython的加载，或者NLTK和SpaCy都是有用的</li>
</ul>
<p>特别是对于视觉，我们已经创建了一个名为torchvision的软件包，它具有常用数据集的数据加载器，如Imagenet，CIFAR10，MNIST等，以及图像数据转换器，即torchvision.datasets 和 torch.utils.data.DataLoader。  </p>
<p>这提供了巨大的便利并避免了编写样板代码。  </p>
<p>本例中我们将使用CIFAR-10数据集。它有以下几类： ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。在CIFAR-10数据集中的数据大小是3<em>32</em>32，例如尺寸为32x32像素的3通道彩色图像。  </p>
<p><img src="https://pytorch.org/tutorials/_images/cifar10.png" alt>  </p>
<h2 id="训练一个图像分类器"><a href="#训练一个图像分类器" class="headerlink" title="训练一个图像分类器"></a>训练一个图像分类器</h2><ul>
<li>使用torchvision加载并归一化（normalizing）CIFAR10训练和测试数据集。</li>
<li>定义一个卷积神经网络  </li>
<li>定义一个损失函数</li>
<li>在训练集上训练网络  </li>
<li>在测试集上测试数据  </li>
</ul>
<ol>
<li>加载和归一化CIFAR10  </li>
</ol>
<p>torchvison能够很简单的加载CIFAR10。  </p>
<pre><code>import torch  
import torchvision  
import torchvision.transforms as transforms  
</code></pre><p>torchvision数集的输出是范围为[0, 1]的PILImage图像。我们将其转换为归一化范围[-1, 1]的张量。  </p>
<pre><code>transform = transform.Compose([transform])  
</code></pre>
      
    </div>

    

    
    
    
    <div>
      
      <div>
    
    <div style="text-align:center;color:#ccc;font-size:14px;">
        -------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------
    </div>
    
</div>
      
    </div>
    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Pytorch/" rel="tag"><i class="fa fa-tag"></i>Pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/04/Adapting-Grammatical-Error-Correction-Based-on-the-Native-Language-of-Writers-with-Neural-Network-Joint-Models/" rel="next" title="Adapting Grammatical Error Correction Based on the Native Language of Writers with Neural Network Joint Models">
                <i class="fa fa-chevron-left"></i> Adapting Grammatical Error Correction Based on the Native Language of Writers with Neural Network Joint Models
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/09/Fast-and-Robust-Neural-Network-Joint-Models-for-Statistical-Machine-md/" rel="prev" title="Fast and Robust Neural Network Joint Models for Statistical Machine.md">
                Fast and Robust Neural Network Joint Models for Statistical Machine.md <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Xiao</p>
              <div class="site-description motion-element" itemprop="description">怕什么真理无穷，进一寸有进一寸的欢喜。</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">36</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/xiaoxiaoAurora" title="GitHub &rarr; https://github.com/xiaoxiaoAurora" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="/uliuxiao@163.com" title="E-Mail &rarr; uliuxiao@163.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-globe"></i>
                神奇的链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://xiaoxiaoaurora.github.io/about/" title="https://xiaoxiaoaurora.github.io/about/">关于此博客</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Learning-with-PyTorch-A-60-Minute-Blitz"><span class="nav-number">1.</span> <span class="nav-text">Deep Learning with PyTorch:A 60 Minute Blitz  </span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#一、PyTorch-是什么"><span class="nav-number">2.</span> <span class="nav-text">一、PyTorch 是什么</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#开始"><span class="nav-number">2.1.</span> <span class="nav-text">开始</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#张量（Tensors"><span class="nav-number">2.1.1.</span> <span class="nav-text">张量（Tensors)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#操作（Operations）"><span class="nav-number">2.1.2.</span> <span class="nav-text">操作（Operations）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NumPy-Bridge"><span class="nav-number">2.2.</span> <span class="nav-text">NumPy Bridge</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-张量"><span class="nav-number">2.3.</span> <span class="nav-text">CUDA 张量</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Autograd-自动求导（automatic-differentiation）"><span class="nav-number">3.</span> <span class="nav-text">Autograd: 自动求导（automatic differentiation）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensor"><span class="nav-number">3.1.</span> <span class="nav-text">Tensor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度"><span class="nav-number">3.2.</span> <span class="nav-text">梯度</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络（Neural-Networks）"><span class="nav-number">4.</span> <span class="nav-text">神经网络（Neural Networks）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#定义网络"><span class="nav-number">4.1.</span> <span class="nav-text">定义网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#损失函数（Loss-Function）"><span class="nav-number">4.2.</span> <span class="nav-text">损失函数（Loss Function）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#反向传播（Backprop）"><span class="nav-number">4.3.</span> <span class="nav-text">反向传播（Backprop）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更新权重"><span class="nav-number">4.4.</span> <span class="nav-text">更新权重</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#训练分类器（Training-a-classifier）"><span class="nav-number">5.</span> <span class="nav-text">训练分类器（Training a classifier）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#What-about-Data"><span class="nav-number">5.1.</span> <span class="nav-text">What about Data?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练一个图像分类器"><span class="nav-number">5.2.</span> <span class="nav-text">训练一个图像分类器</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiao</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数"></span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长"></span>
  
</div>








  
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共26.8k字</span>
</div>
        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/affix.js?v=7.1.0"></script>

  <script src="/js/schemes/pisces.js?v=7.1.0"></script>




  
  <script src="/js/scrollspy.js?v=7.1.0"></script>
<script src="/js/post-details.js?v=7.1.0"></script>



  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
  
    <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/love.js"></script>
</body>
</html>

