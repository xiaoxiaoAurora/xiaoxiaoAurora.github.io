<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Semantic Role Labeling for Learner Chinese--the Importance of Syntactic Parsing and L2-L1 Parallel Data]]></title>
    <url>%2F2019%2F04%2F04%2FSemantic%20Role%20Labeling%20for%20Learner%20Chinese%2F</url>
    <content type="text"><![CDATA[Semantic Role Labeling for Learner Chinese–the Importance of Syntactic Parsing and L2-L1 Parallel Data 摘要 中介语的语义依存标注 taking semantic role labeling (SRL) as a case task and learner Chinese as a case language]]></content>
      <categories>
        <category>Papers</category>
        <category>SRL</category>
      </categories>
      <tags>
        <tag>Papers</tag>
        <tag>SRL</tag>
        <tag>Annotation Guidelines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之range()在Python3中与python2中的区别]]></title>
    <url>%2F2019%2F04%2F02%2FPython%E4%B9%8Brange-%E5%9C%A8Python3%E4%B8%AD%E4%B8%8Epython2%E4%B8%AD%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Python | range()在Python3中与python2中的区别python2中的range返回的是一个列表 python3中的range返回的是一个迭代值]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>range</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | @classmethod @staticmethod区别]]></title>
    <url>%2F2018%2F08%2F20%2FPython%E4%B8%AD%40classmethod%20%40staticmethod%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Python | @classmethod @staticmethod区别Python中有三种方式定义类方法： 常规方法； @classmethod修饰方法； @staticmathod修饰方式。 执行： 输出： 1. 定义方式普通的类方法foo()需要通过self参数隐式的传递当前类对象的实例。@classmethod修饰的方法class_foo()需要通过cls参数传递当前的类对象。@staticmethod修饰的方法定义与普通函数是一样的。 self和cls的区别不是强制的，只是PEP8中一种编程风格，self通常用作实例方法的第一参数，cls通常用作类方法的第一参数。即通常用self来传递当前类对象的实例，cls传递当前类对象。 2. 绑定对象# foo方法绑定对象A的实例，class_foo方法绑定对象A，static_foo没有参数绑定 &gt;&gt;&gt; print(a.foo) 输出： &gt;&gt;&gt; print(a.class_foo) &lt;bound method A.class_foo of &lt;class &apos;__main__.A&apos;&gt;&gt; &gt;&gt;&gt; print(a.static_foo) &lt;function A.static_foo at 0x000001A1026F5840&gt; 3. 调用方式foo可通过实例a调用，类对象A直接调用会参数错误。 &gt;&gt;&gt; a.foo(l) 输出： A.foo(1) 输出： 但foo如下方式可以使用正常，显式的传递实例参数a。 A.foo(a, 1) 输出： class_foo通过类对象或对象实例调用。 &gt;&gt;&gt; A.class_foo(1) 输出： &gt;&gt;&gt; a.class_foo(1) 输出：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅读笔记 | 语言和认知中的跨语言影响]]></title>
    <url>%2F2018%2F08%2F10%2F%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9A%E8%AF%AD%E8%A8%80%E5%92%8C%E8%AE%A4%E7%9F%A5%E4%B8%AD%E7%9A%84%E8%B7%A8%E8%AF%AD%E8%A8%80%E5%BD%B1%E5%93%8D%2F</url>
    <content type="text"><![CDATA[阅读笔记 | 语言和认知中的跨语言影响 Crosslinguistic Influence 跨语言影响,CLI Preface我们对于CLI所了解的内容与那些尚待发现的内容相比起来无疑是相形见绌的，但是，自1989年起，关于CLI的研究早已经进入了一个新的时代。与之前在transfer上的工作相比，新的时代表现出了四种特征。 第一，CLI不再是一种没有原则标准来确定其在语言数据中存在或不存在的现象(cf. Meisel, 1983)。 第二，CLI不再被研究者们简单地视为一个背景（background）、中介（mediating）或者中介变量（intervening variable），只是作为一种解释（例如，对所讨论的语言行为的解释），但从来不作为一个待解释的项（例如，要解释的现象）。 这里有点绕，贴出原文 第三，在Transfer研究的新时代下，CLI不再是一个缺乏明确的理论地位的模糊概念。的确，本书的主要目标是探索、突出和详细地阐述其跨学科理论的发展现状 最后，现在对CLI的本质的研究已经超出了语言知识的范畴，并深入探讨了CLI的认知基础。]]></content>
      <categories>
        <category>Papers</category>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>Papers</tag>
        <tag>CLI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP|中英文名词对照附录]]></title>
    <url>%2F2018%2F07%2F23%2FNLP%E4%B9%8B%E4%B8%AD%E8%8B%B1%E6%96%87%E5%90%8D%E8%AF%8D%E5%AF%B9%E7%85%A7%2F</url>
    <content type="text"><![CDATA[NLP|中英文名词对照附录英语不好，记性差，碰到专业术语总是抓狂（@_@）。主要是一些缩略词、语言学常用词。 句法标注 TLE: Treebank of Learner English 学习者英语树库 SALLE: Syntacticlly Annotating Learner Language of English 英语学习者语言的句法标注（也是一个treebank） UD: Universal Dependencies 通用依存 POS： Part of Speech 词性 Literal Annotation 字面标注 Lemma 词元 Dependency Annotation 依存标注 Word Segmentation 分词；中文切词（即把一句话分成一个词的序列。） Morphological 形态学的; 构形 morphologically 词法地；形态学上地 morphology 形态学，形态论；[语] 词法，[语] 词态学 morph 词态；语素；变体 morpheme [语] 词素；形态素 Distributional 分布式的； 分布 distributive [语] 分配词 Word formation 构词 词性转换 单词构成 linguistic form 语言形式(如后缀、词素、单词、短词、句子等); 语言形态; 语言结构 otheractivation 激活值activation function 激活函数additive noise 加性噪声autoencoder 自编码器Autoencoders 自编码算法average firing rate 平均激活率average sum-of-squares error 均方差backpropagation 后向传播basis 基basis feature vectors 特征基向量batch gradient ascent 批量梯度上升法Bayesian regularization method 贝叶斯规则化方法Bernoulli random variable 伯努利随机变量bias term 偏置项binary classfication 二元分类class labels 类型标记concatenation 级联conjugate gradient 共轭梯度contiguous groups 联通区域convex optimization software 凸优化软件convolution 卷积cost function 代价函数covariance matrix 协方差矩阵DC component 直流分量decorrelation 去相关degeneracy 退化demensionality reduction 降维derivative 导函数diagonal 对角线diffusion of gradients 梯度的弥散eigenvalue 特征值eigenvector 特征向量error term 残差feature matrix 特征矩阵feature standardization 特征标准化feedforward architectures 前馈结构算法feedforward neural network 前馈神经网络feedforward pass 前馈传导fine-tuned 微调first-order feature 一阶特征forward pass 前向传导forward propagation 前向传播Gaussian prior 高斯先验概率generative model 生成模型gradient descent 梯度下降Greedy layer-wise training 逐层贪婪训练方法grouping matrix 分组矩阵Hadamard product 阿达马乘积Hessian matrix Hessian 矩阵hidden layer 隐含层hidden units 隐藏神经元Hierarchical grouping 层次型分组higher-order features 更高阶特征highly non-convex optimization problem 高度非凸的优化问题histogram 直方图hyperbolic tangent 双曲正切函数hypothesis 估值，假设identity activation function 恒等激励函数IID 独立同分布illumination 照明inactive 抑制independent component analysis 独立成份分析input domains 输入域input layer 输入层intensity 亮度/灰度intercept term 截距KL divergence 相对熵KL divergence KL分散度k-Means K-均值learning rate 学习速率least squares 最小二乘法linear correspondence 线性响应linear superposition 线性叠加line-search algorithm 线搜索算法local mean subtraction 局部均值消减local optima 局部最优解logistic regression 逻辑回归loss function 损失函数low-pass filtering 低通滤波magnitude 幅值MAP 极大后验估计maximum likelihood estimation 极大似然估计mean 平均值MFCC Mel 倒频系数multi-class classification 多元分类neural networks 神经网络neuron 神经元Newton’s method 牛顿法non-convex function 非凸函数non-linear feature 非线性特征norm 范式norm bounded 有界范数norm constrained 范数约束normalization 归一化numerical roundoff errors 数值舍入误差numerically checking 数值检验numerically reliable 数值计算上稳定object detection 物体检测objective function 目标函数off-by-one error 缺位错误orthogonalization 正交化output layer 输出层overall cost function 总体代价函数over-complete basis 超完备基over-fitting 过拟合parts of objects 目标的部件part-whole decompostion 部分-整体分解PCA 主元分析penalty term 惩罚因子per-example mean subtraction 逐样本均值消减pooling 池化pretrain 预训练principal components analysis 主成份分析quadratic constraints 二次约束RBMs 受限Boltzman机reconstruction based models 基于重构的模型reconstruction cost 重建代价reconstruction term 重构项redundant 冗余reflection matrix 反射矩阵regularization 正则化regularization term 正则化项rescaling 缩放robust 鲁棒性run 行程second-order feature 二阶特征sigmoid activation function S型激励函数significant digits 有效数字singular value 奇异值singular vector 奇异向量smoothed L1 penalty 平滑的L1范数惩罚Smoothed topographic L1 sparsity penalty 平滑地形L1稀疏惩罚函数smoothing 平滑Softmax Regresson Softmax回归sorted in decreasing order 降序排列source features 源特征sparse autoencoder 消减归一化Sparsity 稀疏性sparsity parameter 稀疏性参数sparsity penalty 稀疏惩罚square function 平方函数squared-error 方差stationary 平稳性（不变性）stationary stochastic process 平稳随机过程step-size 步长值supervised learning 监督学习symmetric positive semi-definite matrix 对称半正定矩阵symmetry breaking 对称失效tanh function 双曲正切函数the average activation 平均活跃度the derivative checking method 梯度验证方法the empirical distribution 经验分布函数the energy function 能量函数the Lagrange dual 拉格朗日对偶函数the log likelihood 对数似然函数the pixel intensity value 像素灰度值the rate of convergence 收敛速度topographic cost term 拓扑代价项topographic ordered 拓扑秩序transformation 变换translation invariant 平移不变性trivial answer 平凡解under-complete basis 不完备基unrolling 组合扩展unsupervised learning 无监督学习variance 方差vecotrized implementation 向量化实现vectorization 矢量化visual cortex 视觉皮层weight decay 权重衰减weighted average 加权平均值whitening 白化zero-mean 均值为零 Letter AAccumulated error backpropagation 累积误差逆传播Activation Function 激活函数Adaptive Resonance Theory/ART 自适应谐振理论Addictive model 加性学习Adversarial Networks 对抗网络Affine Layer 仿射层Affinity matrix 亲和矩阵Agent 代理 / 智能体Algorithm 算法Alpha-beta pruning α-β剪枝Anomaly detection 异常检测Approximation 近似Area Under ROC Curve／AUC Roc 曲线下面积Artificial General Intelligence/AGI 通用人工智能Artificial Intelligence/AI 人工智能Association analysis 关联分析Attention mechanism 注意力机制Attribute conditional independence assumption 属性条件独立性假设Attribute space 属性空间Attribute value 属性值Autoencoder 自编码器Automatic speech recognition 自动语音识别Automatic summarization 自动摘要Average gradient 平均梯度Average-Pooling 平均池化 Letter BBackpropagation Through Time 通过时间的反向传播Backpropagation/BP 反向传播Base learner 基学习器Base learning algorithm 基学习算法Batch Normalization/BN 批量归一化Bayes decision rule 贝叶斯判定准则Bayes Model Averaging／BMA 贝叶斯模型平均Bayes optimal classifier 贝叶斯最优分类器Bayesian decision theory 贝叶斯决策论Bayesian network 贝叶斯网络Between-class scatter matrix 类间散度矩阵Bias 偏置 / 偏差Bias-variance decomposition 偏差-方差分解Bias-Variance Dilemma 偏差 – 方差困境Bi-directional Long-Short Term Memory/Bi-LSTM 双向长短期记忆Binary classification 二分类Binomial test 二项检验Bi-partition 二分法Boltzmann machine 玻尔兹曼机Bootstrap sampling 自助采样法／可重复采样／有放回采样Bootstrapping 自助法Break-Event Point／BEP 平衡点 Letter CCalibration 校准Cascade-Correlation 级联相关Categorical attribute 离散属性Class-conditional probability 类条件概率Classification and regression tree/CART 分类与回归树Classifier 分类器Class-imbalance 类别不平衡Closed -form 闭式Cluster 簇/类/集群Cluster analysis 聚类分析Clustering 聚类Clustering ensemble 聚类集成Co-adapting 共适应Coding matrix 编码矩阵COLT 国际学习理论会议Committee-based learning 基于委员会的学习Competitive learning 竞争型学习Component learner 组件学习器Comprehensibility 可解释性Computation Cost 计算成本Computational Linguistics 计算语言学Computer vision 计算机视觉Concept drift 概念漂移Concept Learning System /CLS 概念学习系统Conditional entropy 条件熵Conditional mutual information 条件互信息Conditional Probability Table／CPT 条件概率表Conditional random field/CRF 条件随机场Conditional risk 条件风险Confidence 置信度Confusion matrix 混淆矩阵Connection weight 连接权Connectionism 连结主义Consistency 一致性／相合性Contingency table 列联表Continuous attribute 连续属性Convergence 收敛Conversational agent 会话智能体Convex quadratic programming 凸二次规划Convexity 凸性Convolutional neural network/CNN 卷积神经网络Co-occurrence 同现Correlation coefficient 相关系数Cosine similarity 余弦相似度Cost curve 成本曲线Cost Function 成本函数Cost matrix 成本矩阵Cost-sensitive 成本敏感Cross entropy 交叉熵Cross validation 交叉验证Crowdsourcing 众包Curse of dimensionality 维数灾难Cut point 截断点Cutting plane algorithm 割平面法 Letter DData mining 数据挖掘Data set 数据集Decision Boundary 决策边界Decision stump 决策树桩Decision tree 决策树／判定树Deduction 演绎Deep Belief Network 深度信念网络Deep Convolutional Generative Adversarial Network/DCGAN 深度卷积生成对抗网络Deep learning 深度学习Deep neural network/DNN 深度神经网络Deep Q-Learning 深度 Q 学习Deep Q-Network 深度 Q 网络Density estimation 密度估计Density-based clustering 密度聚类Differentiable neural computer 可微分神经计算机Dimensionality reduction algorithm 降维算法Directed edge 有向边Disagreement measure 不合度量Discriminative model 判别模型Discriminator 判别器Distance measure 距离度量Distance metric learning 距离度量学习Distribution 分布Divergence 散度Diversity measure 多样性度量／差异性度量Domain adaption 领域自适应Downsampling 下采样D-separation （Directed separation） 有向分离Dual problem 对偶问题Dummy node 哑结点Dynamic Fusion 动态融合Dynamic programming 动态规划 Letter EEigenvalue decomposition 特征值分解Embedding 嵌入Emotional analysis 情绪分析Empirical conditional entropy 经验条件熵Empirical entropy 经验熵Empirical error 经验误差Empirical risk 经验风险End-to-End 端到端Energy-based model 基于能量的模型Ensemble learning 集成学习Ensemble pruning 集成修剪Error Correcting Output Codes／ECOC 纠错输出码Error rate 错误率Error-ambiguity decomposition 误差-分歧分解Euclidean distance 欧氏距离Evolutionary computation 演化计算Expectation-Maximization 期望最大化Expected loss 期望损失Exploding Gradient Problem 梯度爆炸问题Exponential loss function 指数损失函数Extreme Learning Machine/ELM 超限学习机 Letter FFactorization 因子分解False negative 假负类False positive 假正类False Positive Rate/FPR 假正例率Feature engineering 特征工程Feature selection 特征选择Feature vector 特征向量Featured Learning 特征学习Feedforward Neural Networks/FNN 前馈神经网络Fine-tuning 微调Flipping output 翻转法Fluctuation 震荡Forward stagewise algorithm 前向分步算法Frequentist 频率主义学派Full-rank matrix 满秩矩阵Functional neuron 功能神经元 Letter GGain ratio 增益率Game theory 博弈论Gaussian kernel function 高斯核函数Gaussian Mixture Model 高斯混合模型General Problem Solving 通用问题求解Generalization 泛化Generalization error 泛化误差Generalization error bound 泛化误差上界Generalized Lagrange function 广义拉格朗日函数Generalized linear model 广义线性模型Generalized Rayleigh quotient 广义瑞利商Generative Adversarial Networks/GAN 生成对抗网络Generative Model 生成模型Generator 生成器Genetic Algorithm/GA 遗传算法Gibbs sampling 吉布斯采样Gini index 基尼指数Global minimum 全局最小Global Optimization 全局优化Gradient boosting 梯度提升Gradient Descent 梯度下降Graph theory 图论Ground-truth 真相／真实 Letter HHard margin 硬间隔Hard voting 硬投票Harmonic mean 调和平均Hesse matrix 海塞矩阵Hidden dynamic model 隐动态模型Hidden layer 隐藏层Hidden Markov Model/HMM 隐马尔可夫模型Hierarchical clustering 层次聚类Hilbert space 希尔伯特空间Hinge loss function 合页损失函数Hold-out 留出法Homogeneous 同质Hybrid computing 混合计算Hyperparameter 超参数Hypothesis 假设Hypothesis test 假设验证 Letter IICML 国际机器学习会议Improved iterative scaling/IIS 改进的迭代尺度法Incremental learning 增量学习Independent and identically distributed/i.i.d. 独立同分布Independent Component Analysis/ICA 独立成分分析Indicator function 指示函数Individual learner 个体学习器Induction 归纳Inductive bias 归纳偏好Inductive learning 归纳学习Inductive Logic Programming／ILP 归纳逻辑程序设计Information entropy 信息熵Information gain 信息增益Input layer 输入层Insensitive loss 不敏感损失Inter-cluster similarity 簇间相似度International Conference for Machine Learning/ICML 国际机器学习大会Intra-cluster similarity 簇内相似度Intrinsic value 固有值Isometric Mapping/Isomap 等度量映射Isotonic regression 等分回归Iterative Dichotomiser 迭代二分器 Letter KKernel method 核方法Kernel trick 核技巧Kernelized Linear Discriminant Analysis／KLDA 核线性判别分析K-fold cross validation k 折交叉验证／k 倍交叉验证K-Means Clustering K – 均值聚类K-Nearest Neighbours Algorithm/KNN K近邻算法Knowledge base 知识库Knowledge Representation 知识表征 Letter LLabel space 标记空间Lagrange duality 拉格朗日对偶性Lagrange multiplier 拉格朗日乘子Laplace smoothing 拉普拉斯平滑Laplacian correction 拉普拉斯修正Latent Dirichlet Allocation 隐狄利克雷分布Latent semantic analysis 潜在语义分析Latent variable 隐变量Lazy learning 懒惰学习Learner 学习器Learning by analogy 类比学习Learning rate 学习率Learning Vector Quantization/LVQ 学习向量量化Least squares regression tree 最小二乘回归树Leave-One-Out/LOO 留一法linear chain conditional random field 线性链条件随机场Linear Discriminant Analysis／LDA 线性判别分析Linear model 线性模型Linear Regression 线性回归Link function 联系函数Local Markov property 局部马尔可夫性Local minimum 局部最小Log likelihood 对数似然Log odds／logit 对数几率Logistic Regression Logistic 回归Log-likelihood 对数似然Log-linear regression 对数线性回归Long-Short Term Memory/LSTM 长短期记忆Loss function 损失函数 Letter MMachine translation/MT 机器翻译Macron-P 宏查准率Macron-R 宏查全率Majority voting 绝对多数投票法Manifold assumption 流形假设Manifold learning 流形学习Margin theory 间隔理论Marginal distribution 边际分布Marginal independence 边际独立性Marginalization 边际化Markov Chain Monte Carlo/MCMC 马尔可夫链蒙特卡罗方法Markov Random Field 马尔可夫随机场Maximal clique 最大团Maximum Likelihood Estimation/MLE 极大似然估计／极大似然法Maximum margin 最大间隔Maximum weighted spanning tree 最大带权生成树Max-Pooling 最大池化Mean squared error 均方误差Meta-learner 元学习器Metric learning 度量学习Micro-P 微查准率Micro-R 微查全率Minimal Description Length/MDL 最小描述长度Minimax game 极小极大博弈Misclassification cost 误分类成本Mixture of experts 混合专家Momentum 动量Moral graph 道德图／端正图Multi-class classification 多分类Multi-document summarization 多文档摘要Multi-layer feedforward neural networks 多层前馈神经网络Multilayer Perceptron/MLP 多层感知器Multimodal learning 多模态学习Multiple Dimensional Scaling 多维缩放Multiple linear regression 多元线性回归Multi-response Linear Regression ／MLR 多响应线性回归Mutual information 互信息 Letter NNaive bayes 朴素贝叶斯Naive Bayes Classifier 朴素贝叶斯分类器Named entity recognition 命名实体识别Nash equilibrium 纳什均衡Natural language generation/NLG 自然语言生成Natural language processing 自然语言处理Negative class 负类Negative correlation 负相关法Negative Log Likelihood 负对数似然Neighbourhood Component Analysis/NCA 近邻成分分析Neural Machine Translation 神经机器翻译Neural Turing Machine 神经图灵机Newton method 牛顿法NIPS 国际神经信息处理系统会议No Free Lunch Theorem／NFL 没有免费的午餐定理Noise-contrastive estimation 噪音对比估计Nominal attribute 列名属性Non-convex optimization 非凸优化Nonlinear model 非线性模型Non-metric distance 非度量距离Non-negative matrix factorization 非负矩阵分解Non-ordinal attribute 无序属性Non-Saturating Game 非饱和博弈Norm 范数Normalization 归一化Nuclear norm 核范数Numerical attribute 数值属性 Letter OObjective function 目标函数Oblique decision tree 斜决策树Occam’s razor 奥卡姆剃刀Odds 几率Off-Policy 离策略One shot learning 一次性学习One-Dependent Estimator／ODE 独依赖估计On-Policy 在策略Ordinal attribute 有序属性Out-of-bag estimate 包外估计Output layer 输出层Output smearing 输出调制法Overfitting 过拟合／过配Oversampling 过采样 Letter PPaired t-test 成对 t 检验Pairwise 成对型Pairwise Markov property 成对马尔可夫性Parameter 参数Parameter estimation 参数估计Parameter tuning 调参Parse tree 解析树Particle Swarm Optimization/PSO 粒子群优化算法Part-of-speech tagging 词性标注Perceptron 感知机Performance measure 性能度量Plug and Play Generative Network 即插即用生成网络Plurality voting 相对多数投票法Polarity detection 极性检测Polynomial kernel function 多项式核函数Pooling 池化Positive class 正类Positive definite matrix 正定矩阵Post-hoc test 后续检验Post-pruning 后剪枝potential function 势函数Precision 查准率／准确率Prepruning 预剪枝Principal component analysis/PCA 主成分分析Principle of multiple explanations 多释原则Prior 先验Probability Graphical Model 概率图模型Proximal Gradient Descent/PGD 近端梯度下降Pruning 剪枝Pseudo-label 伪标记 Letter QQuantized Neural Network 量子化神经网络Quantum computer 量子计算机Quantum Computing 量子计算Quasi Newton method 拟牛顿法 Letter RRadial Basis Function／RBF 径向基函数Random Forest Algorithm 随机森林算法Random walk 随机漫步Recall 查全率／召回率Receiver Operating Characteristic/ROC 受试者工作特征Rectified Linear Unit/ReLU 线性修正单元Recurrent Neural Network 循环神经网络Recursive neural network 递归神经网络Reference model 参考模型Regression 回归Regularization 正则化Reinforcement learning/RL 强化学习Representation learning 表征学习Representer theorem 表示定理reproducing kernel Hilbert space/RKHS 再生核希尔伯特空间Re-sampling 重采样法Rescaling 再缩放Residual Mapping 残差映射Residual Network 残差网络Restricted Boltzmann Machine/RBM 受限玻尔兹曼机Restricted Isometry Property/RIP 限定等距性Re-weighting 重赋权法Robustness 稳健性/鲁棒性Root node 根结点Rule Engine 规则引擎Rule learning 规则学习 Letter SSaddle point 鞍点Sample space 样本空间Sampling 采样Score function 评分函数Self-Driving 自动驾驶Self-Organizing Map／SOM 自组织映射Semi-naive Bayes classifiers 半朴素贝叶斯分类器Semi-Supervised Learning 半监督学习semi-Supervised Support Vector Machine 半监督支持向量机Sentiment analysis 情感分析Separating hyperplane 分离超平面Sigmoid function Sigmoid 函数Similarity measure 相似度度量Simulated annealing 模拟退火Simultaneous localization and mapping 同步定位与地图构建Singular Value Decomposition 奇异值分解Slack variables 松弛变量Smoothing 平滑Soft margin 软间隔Soft margin maximization 软间隔最大化Soft voting 软投票Sparse representation 稀疏表征Sparsity 稀疏性Specialization 特化Spectral Clustering 谱聚类Speech Recognition 语音识别Splitting variable 切分变量Squashing function 挤压函数Stability-plasticity dilemma 可塑性-稳定性困境Statistical learning 统计学习Status feature function 状态特征函Stochastic gradient descent 随机梯度下降Stratified sampling 分层采样Structural risk 结构风险Structural risk minimization/SRM 结构风险最小化Subspace 子空间Supervised learning 监督学习／有导师学习support vector expansion 支持向量展式Support Vector Machine/SVM 支持向量机Surrogat loss 替代损失Surrogate function 替代函数Symbolic learning 符号学习Symbolism 符号主义Synset 同义词集 Letter TT-Distribution Stochastic Neighbour Embedding/t-SNE T – 分布随机近邻嵌入Tensor 张量Tensor Processing Units/TPU 张量处理单元The least square method 最小二乘法Threshold 阈值Threshold logic unit 阈值逻辑单元Threshold-moving 阈值移动Time Step 时间步骤Tokenization 标记化Training error 训练误差Training instance 训练示例／训练例Transductive learning 直推学习Transfer learning 迁移学习Treebank 树库Tria-by-error 试错法True negative 真负类True positive 真正类True Positive Rate/TPR 真正例率Turing Machine 图灵机Twice-learning 二次学习 Letter UUnderfitting 欠拟合／欠配Undersampling 欠采样Understandability 可理解性Unequal cost 非均等代价Unit-step function 单位阶跃函数Univariate decision tree 单变量决策树Unsupervised learning 无监督学习／无导师学习Unsupervised layer-wise training 无监督逐层训练Upsampling 上采样 Letter VVanishing Gradient Problem 梯度消失问题Variational inference 变分推断VC Theory VC维理论Version space 版本空间Viterbi algorithm 维特比算法Von Neumann architecture 冯 · 诺伊曼架构 Letter WWasserstein GAN/WGAN Wasserstein生成对抗网络Weak learner 弱学习器Weight 权重Weight sharing 权共享Weighted voting 加权投票法Within-class scatter matrix 类内散度矩阵Word embedding 词嵌入Word sense disambiguation 词义消歧 Letter ZZero-data learning 零数据学习Zero-shot learning 零次学习 Aapproximations近似值arbitrary随意的affine仿射的arbitrary任意的amino acid氨基酸amenable经得起检验的axiom公理，原则abstract提取architecture架构，体系结构；建造业absolute绝对的arsenal军火库assignment分配algebra线性代数asymptotically无症状的appropriate恰当的 Bbias偏差brevity简短，简洁；短暂broader广泛briefly简短的batch批量 Cconvergence 收敛，集中到一点convex凸的contours轮廓constraint约束constant常理commercial商务的complementarity补充coordinate ascent同等级上升clipping剪下物；剪报；修剪component分量；部件continuous连续的covariance协方差canonical正规的，正则的concave非凸的corresponds相符合；相当；通信corollary推论concrete具体的事物，实在的东西cross validation交叉验证correlation相互关系convention约定cluster一簇centroids 质心，形心converge收敛computationally计算(机)的calculus计算 Dderive获得，取得dual二元的duality二元性；二象性；对偶性derivation求导；得到；起源denote预示，表示，是…的标志；意味着，[逻]指称divergence 散度；发散性dimension尺度，规格；维数dot小圆点distortion变形density概率密度函数discrete离散的discriminative有识别能力的diagonal对角dispersion分散，散开determinant决定因素disjoint不相交的 Eencounter遇到ellipses椭圆equality等式extra额外的empirical经验；观察ennmerate例举，计数exceed超过，越出expectation期望efficient生效的endow赋予explicitly清楚的exponential family指数家族equivalently等价的 Ffeasible可行的forary初次尝试finite有限的，限定的forgo摒弃，放弃fliter过滤frequentist最常发生的forward search前向式搜索formalize使定形 Ggeneralized归纳的generalization概括，归纳；普遍化；判断（根据不足）guarantee保证；抵押品generate形成，产生geometric margins几何边界gap裂口generative生产的；有生产力的 Hheuristic启发式的；启发法；启发程序hone怀恋；磨hyperplane超平面 Linitial最初的implement执行intuitive凭直觉获知的incremental增加的intercept截距intuitious直觉instantiation例子indicator指示物，指示器interative重复的，迭代的integral积分identical相等的；完全相同的indicate表示，指出invariance不变性，恒定性impose把…强加于intermediate中间的interpretation解释，翻译 Jjoint distribution联合概率 Llieu替代logarithmic对数的，用对数表示的latent潜在的Leave-one-out cross validation留一法交叉验证 Mmagnitude巨大mapping绘图，制图；映射matrix矩阵mutual相互的，共同的monotonically单调的minor较小的，次要的multinomial多项的multi-class classification二分类问题 Nnasty讨厌的notation标志，注释naïve朴素的 Oobtain得到oscillate摆动optimization problem最优化问题objective function目标函数optimal最理想的orthogonal(矢量，矩阵等)正交的orientation方向ordinary普通的occasionally偶然的 Ppartial derivative偏导数property性质proportional成比例的primal原始的，最初的permit允许pseudocode伪代码permissible可允许的polynomial多项式preliminary预备precision精度perturbation 不安，扰乱poist假定，设想positive semi-definite半正定的parentheses圆括号posterior probability后验概率plementarity补充pictorially图像的parameterize确定…的参数poisson distribution柏松分布pertinent相关的 Qquadratic二次的quantity量，数量；分量query疑问的 Rregularization使系统化；调整reoptimize重新优化restrict限制；限定；约束reminiscent回忆往事的；提醒的；使人联想…的（of）remark注意random variable随机变量respect考虑respectively各自的；分别的redundant过多的；冗余的 Ssusceptible敏感的stochastic可能的；随机的symmetric对称的sophisticated复杂的spurious假的；伪造的subtract减去；减法器simultaneously同时发生地；同步地suffice满足scarce稀有的，难得的split分解，分离subset子集statistic统计量successive iteratious连续的迭代scale标度sort of有几分的squares平方 Ttrajectory轨迹temporarily暂时的terminology专用名词tolerance容忍；公差thumb翻阅threshold阈，临界theorem定理tangent正弦 Uunit-length vector单位向量 Vvalid有效的，正确的variance方差variable变量；变元vocabulary词汇valued经估价的；宝贵的 Wwrapper包装]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>名词解释</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习记录之句法结构标注(一)]]></title>
    <url>%2F2018%2F07%2F09%2F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%E4%B9%8B%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E6%A0%87%E6%B3%A8%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[学习记录之句法结构标注（一） Note: 关于学习者文本做句法标注 针对汉语学习者尚且没有太多工作，汉语上，香港城市大学有一些相关工作。 大致上是为中介语标注句法结构，进而可以做以下工作，例如给教师提供语言用例的检索、做中介语NLP等。 该篇文章仅是在阅读论文中所做的基础记录，大部分是论文翻译内容。 Information： 中介语（Interlanguage）：也有人译为”过渡语”或”语际语”，是指在第二语言习得过程中，学习者通过一定的学习策略，在目的语输入的基础上所形成的一种既不同于其第一语言也不同于目的语，随着学习的进展向目的语逐渐过渡的动态的语言系统。 一、关于句法标注（Syntactically Annotating）SALLE（Syntactically Annotating Learner Language of English） 从英语学习者文本的句法标注相关内容进行了解。该任务主要就是对把英语作为第二语言的学习者所写的文本进行句法结构标注。该项目中的目标是对给定句子中存在的语言属性进行注释（annotate linguistic properties present），而不是对学习者的意思做出太多解释（interpretation），或者正确的形式应该是什么。为了达到这个目的，我们的注释方案根据句子中的上下文，并基于英语规则（目标语言），添加了几个关于每个单词的语言信息。 我们通过对依存关系进行注解来标记句子中的单词之间的句法关系，例如，一个词是另一个词的主语。 A beta version of the guidelines we are using are available here.The decisions we have made (certainly needing refinement in some cases) point out many of the essential questions that need to be addressed for linguistically annotating learner data, and we hope they can stimulate discussion. —-以上摘自（http://cl.indiana.edu/~salle/） 二、论文研读–《Universal Dependencies for Learner English》 Abstract: 本篇论文主要介绍了英语学习者的树库（TLE），是一个将英语作为第二语言（ESL）的第一个公共可用的语法树库（syntactic treebank）。TLE为5124个句子提供了手动注释的POS标签和通用依存（Universal Dependency，UD）树，这些句子来源于剑桥大学FCE（First Certificate in English ）语料库。UD注解和FCE中已存在的错误注解结合在一起，从而为每个句子的原始版本和错误修正后的版本提供完整的语法分析。进一步的描述了ESL注释指南，该指南允许对不符合语法的英语进行一致的句法处理。最后，在TLE数据集上对POS标记和依存关系解析性能进行基准测试，并测量语法错误对解析准确性的影响。我们设想树库支持第二语言习得的广泛的语言和计算研究以及自动处理不符合语法的语言。 1、Introduction大多数世界范围内可用的英语文本都是由非母语者所产生的。这些文本中最明显的挑战就是语法错误，解决这些问题对于语言习得的科学研究和自然语言处理都是至关重要的。尽管非母语英语无处不在，但是目前还没有公共可用的ESL句法树库。为了解决这个问题，我们提出了英语学习者树库（TLE，theTreebank of Learner English），这是非英语母语的第一个资源，树库包含用POS标签和依存树手动注释的5,124个句子。 TLE句子是从FCE数据集中获取，这些句子是由来自10个不同母语背景的英语学习者所写。 treebank使用了通用依存(UD)形式主义，提供跨不同语言的统一注释框架，且面向多语种NLP。 以上两种使得treebank能够支持ESL的计算分析，它不仅使用基于英语的，而且还使用多种语言的方法，试图将ESL现象与本地语言语法联系起来。 以学习者语言分析之前的工作为基础，制定了一套附加的注解约定，旨在对不符合语法的学习者语言进行统一处理。采用一个two-layer 分析，在这个分析中，每个句子的原始版本和纠正版本都提供了不同的语法注释。该方法是通过FCE语料中已存在的错误注释而启用的，该注释用于生成数据集的错误修正变体。 总的来说这篇论文主要有以下三点贡献： 为ESL引入了第一个大型语法树库，该树库包括手工注释的POS标签和通用依存（UD）。 为不符合语法的学习者英语描述了一种受语言驱动的注释方案，并通过注释者间协议分析为其一致性提供经验支持。 作者在自己的数据集上对性能最佳的解析器进行了基准测试，并且评估了自动进行POS标注和依存分析的精确度对语法错误的影响。 论文结构说明： Section 2：Present an overview of the treebank. Section 3 and Section 4:Provide background information on the annotation project, and review the main annotation stages leading to the current form of the dataset. Section 5: To Summary the ESL annotation guidelines. Section 6: Present the Inter-annotator agreement analysis. Section 7: Parsing Experiments. Section 8: Related Work Section 9: Conclusion 2、Treebank概述 使用的是NLTL句子分词器（http://www.nltk.org/api/nltk.tokenize.html）的改编版进行句子级别切分。Word level tokenization was generated using the Stanford PTB word tokenizer（http://nlp.stanford.edu/software/tokenizer.shtml）。 TLE是第一个以完全手动注释的方式构建的大规模英语树库。 TLE包含5124个英语通用依赖关系(UD)形式中带有POS标记和依存注释的句子。这些句子是从FCE语料得到，这是一组中高级英语学习者所写的文章，包含75个错误分类的错误注释。 树库中的学习者来自10个母语不同的语言背景：汉语、法语、德语、意大利语、日语、韩语、葡萄牙语、西班牙语、俄语和土耳其语。每种母语背景下都随机挑选500个自动分段的句子，除此之外所选的句子必须至少包含一种不是符号或拼写的语法错误。 TLE注解有两个版本： 学习者写的原始句子（有语法错误）； 纠正的句子，是原始句子的语法变体，根据FCE数据集提供的手动错误注释纠正了句子中的所有语法错误。 由此产生的正确句子构成了标准英语的平行语料库。 3、Annotator Training手动注释人员的相关培训 4、Annotation Procedure树库的形成分注释、审核、分歧解决和有针对性的调试四个步骤。 4.1、Annotation annotation from scratch. 我们使用一个基于CoNLL的文本模板(textual template)，其中每个单词在单独的行（line）中进行注释，每一行包含六列(根据英语UD指南 Version 1)： index(IND) the word itself(WORD) a Universal POS tag(UPOS) a Penn Treebank POS tag(POS) a head word index(HIND) a dependency relation(REL) 下图示例是展示给注释者的预先注释的原始句子： 4.2、review所有带注释的句子以双盲的方式被随机分配给第二个注释器(也称 reviewer)。reviewer的任务是标记所有注释不同的注释。 为方便review的工作，编辑了一个常见的注解错误列表（可在已发布的注释手册中找到）。 引入了一个主动编辑注释的方案来进行review，该方案可以避免reviewer由于passive approval而忽略注释问题。具体来讲： 4.3、Disagreement Resolution在注解过程的最后一步里，所有的annotator-reviewer分歧对由第三个注释器解决(annotator，henceforth judge)，其主要任务是在annotator和reviewer之间做出选择。主要是以下两个任务： 评审人员可以用第三种替代方法解决注释或评论意见的分歧，并为审阅人员所忽略的注释问题引入新的更正。 另一项任务是为通过审查异议或出现在句子中的歧义结构标记可接受的替代注释（mark acceptable alternative annotations）。 4.4、Final Debugging在采用过judge给出的解决方案后，我们用特定的语言学结构的调试测试对语料库进行了查询。附件的测试阶段进一步减少了注释错误的数量和treebank中的不一致性。 5、Annotation Scheme for ESL注解使用英语的UD POS标记和依存关系的现有目录，并遵循英语的标准UD注释指南。这些指导方针是以英语的语法用法来制定的，不包括由于语法错误而产生的非标准句法结构。指导方针遵循字面阅读（literal reading）的一般原则，强调根据观察到的语言使用进行句法分析。该策略延续了SLA中的一项工作，主张围绕形态语法表面依据对学习者语言进行集中分析。 我们的框架包含了对已改正的句子的并行注释，这种策略经常出现在多层注释方案的上下文中，这些注释方案也解释了错误修正的句子形式。 在UD中部署一个字面注释策略，这是一种加强注释跨语言一致性的形式主义，将使作者在英语中的非规范结构和作者的母语中的规范结构之间进行有意义的比较。因此，我们的树库的一个重要的新特性是它支持学习者语言的交叉语言研究的能力。 5.1 Literal Annotation关于词性标注，文字标注意味着尽可能地遵循观察到的词形形式。从句法上讲，参数结构是根据单词的用法进行注释的，而不是根据相关上下文中的典型分布进行注释的。下面的惯例列表定义了一些常见的与语法错误相关的非规范结构的字面阅读的概念: 参数结构、时态、词性转换（构词法？）、 Argument Structure Extraneous prepositions:我们注释所有由外来的介词作为名词修饰词引入的名词依赖性。在下面的句子中，“his”被标记为一个名词修饰语(nmod)而不是“give”的间接宾语(iobj)。 Ommited prepossitions:我们把一个缺少介词的谓语词的名词依赖项作为参数，而不是名词修饰词。例如下面的例子中，将“money”作为一个直接宾语（dobj）而不是视为一个名词修饰语（nmod）,“you”则根据上下文视为一个间接宾语（iobj）而不是一个dobj。 Tense 根据动词的形态学时态，标注错误的时态用法。例如下图中，“shopping”的时态注释为现在分词(present participle)VBG，而校正后的“shop”则被注解为VBP。 Word Formation 字面上注释了在语境上合理并且可以分配PTB标签的错误单词形式。下面例子中“stuffs”就是被视为一个复数名词处理。 类似地，在下面的示例中我们将“necessaryiest”注释为最高级(superlative)。 5.2 Exceptions to Literal Annotation虽然ESL的一般注解策略遵循literal sentence readings，但是有几种类型的构词错误使这种阅读没有信息或不可能，本质上迫使某些词必须用某种程度的解释进行注释。因此，根据从FCE错误纠正中获得的对预定义词的解释，在原句中注释下列情况。 Spelling拼写错误是根据单词的正确拼写形式进行注解的。为了支持自动注释工具的错误分析，关于拼写错误的单词形式的最常见用法，在POS标签的元数据字段TYPO中注释恰好形成有效单词的拼写错误的单词。下图的例子中，TYPO字段包含“where”的典型的POS注释，这在句子的上下文中显然是无意的。 Word Formation不能使用现有的PTB标签分配的错误的词结构会被标注为正确的词形式。 有复数后缀的畸形形容词会接收到一个标准的形容词POS标签。当适用时，这种情况还会在使用属性“ua”的错误注释中获得不必要的协议的附加标记。 错误的构词法导致有效的，但上下文不可信的构词形式也根据词的更正进行注解。在下面的例子中，名词形式的“sale”很可能是一个畸形动词的意外结果。 与导致有效单词的拼写错误类似，我们在TYPO元数据字段中标记典型的文字POS注释。 6 Editing Agreement 7 Parsing ExperimentsTLE可以学习解析学习者语言并探索语法错误和解析性能之间的关系。因此，在数据集上提出了解析基准，并提供了几种评估语法错误降低了自动POS标记和依存解析质量的范围。 第一个实验： measures tagging and parsing accuracy on the TLE and approximates the gloabal impact of grammatical errors on automatic annotation via performance comparison between the original and error corrected sentence versions.]]></content>
      <categories>
        <category>Papers</category>
        <category>Syntactically Annotating</category>
      </categories>
      <tags>
        <tag>Papers</tag>
        <tag>论文阅读笔记</tag>
        <tag>Syntactically Annotating</tag>
        <tag>Universal Dependencies</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文句法结构]]></title>
    <url>%2F2018%2F07%2F03%2F%E4%B8%AD%E6%96%87%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[中文句法结构 参考：NLP+句法结构（三）︱中文句法结构（CIPS2016、依存句法、文法） 自然语言处理中的自然语言句子级分析技术，可以大致分为词法分析、句法分析、语义分析三个层面。第二个层面的句法分析（syntactic parsing）是对输入的文本句子进行分析以得到句子的句法结构的处理过程。对句法结构进行分析，一方面是语言理解的自身需求，句法分析是语言理解的重要一环，另一方面也为其它自然语言处理任务提供支持。例如句法驱动的统计机器翻译需要对源语言或目标语言（或者同时两种语言）进行句法分析；语义分析通常以句法分析的输出结果作为输入以便获得更多的指示信息。 根据句法结构的表示形式不同，最常见的句法分析任务可以分为以下三种： (1) 短语结构句法分析（phrase-structure syntactic parsing），该任务也被称作成分句法分析（constituent syntactic parsing），作用是识别出句子中的短语结构以及短语之间的层次句法关系； (2) 依存句法分析（dependency syntactic parsing），作用是识别句子中词汇与词汇之间的相互依存关系； (3) 深层文法句法分析，即利用深层文法，例如词汇化树邻接文法（Lexicalized Tree Adjoining Grammar， LTAG）、词汇功能文法（Lexical Functional Grammar， LFG）、组合范畴文法（Combinatory Categorial Grammar， CCG）等，对句子进行深层的句法以及语义分析。 上述几种句法分析任务比较而言，依存句法分析属于浅层句法分析。其实现过程相对简单，比较适合在多语言环境下的应用，但是依存句法分析所能提供的信息也相对较少。深层文法句法分析可以提供丰富的句法和语义信息，但是采用的文法相对复杂，分析器的运行复杂度也较高，这使得深层句法分析当前不适合处理大规模数据。短语结构句法分析介于依存句法分析和深层文法句法分析之间。 词法分析是将输入句子从字序列转化为词和词性序列，句法分析将输入句子从词序列形式转化为树状结构，从而刻画句子的词法和句法结构。 摘录自：CIPS2016 中文信息处理报告《第一章 词法和句法分析研究进展、现状及趋势》P8 -P11CIPS2016&gt; 中文信息处理报告下载链接：http://cips-upload.bj.bcebos.com/cips2016.pdf 不同类型的句法分析体现在句法结构的表示形式不同，实现过程的复杂程度也有所不同。因此，科研人员采用不同的方法构建符合各个语法特点的句法分析系统。下文主要对句法分析技术方法和研究现状进行总结分析。 一、依存句法分析依存句法存在一个共同的基本假设：句法结构本质上包含词和词之间的依存（修饰）关系。一个依存关系连接两个词，分别是核心词（head）和依存词（dependent）。依存关系可以细分为不同的类型，表示两个词之间的具体句法关系。 依存句法分析的形式化目标是针对给定输入句子，寻找分值（或概率）最大的依存树 其中， Y(x)表示输入句子x对应的合法依存树集合，即搜索空间； θ 为模型参数， 即特征权重向量。 目前研究主要集中在数据驱动的依存句法分析方法，即在训练实例集合上学习得到依存句法分析器，而不涉及依存语法理论的研究。数据驱动的方法的主要优势在于给定较大规模的训练数据，不需要过多的人工干预，就可以得到比较好的模型。因此，这类方法很容易应用到新领域和新语言环境。数据驱动的依存句法分析方法主要有两种主流方法：基于图（graph-based）的分析方法和基于转移（transition-based）的分析方法。 1、基于图的依存句法分析方法基于图的方法将依存句法分析问题看成从完全有向图中寻找最大生成树的问题。一棵依存树的分值由构成依存树的几种子树的分值累加得到。根据依存树分值中包含的子树的复杂度，基于图的依存分析模型可以简单区分为一阶和高阶模型。高阶模型可以使用更加复杂的子树特征，因此分析准确率更高，但是解码算法的效率也会下降。基于图的方法通常采用基于动态规划的解码算法，也有一些学者采用柱搜索 (beamsearch)来提高效率。学习特征权重时，通常采用在线训练算法，如平均感知（averagedperceptron）。 2、基于转移的依存句法分析方法基于转移的方法将依存树的构成过程建模为一个动作序列，将依存分析问题转化为寻找最优动作序列的问题。 早期，研究者们使用局部分类器（如支持向量机等）决定下一个动作。近年来，研究者们采用全局线性模型来决定下一个动作，一个依存树的分值由其对应的动作序列中每一个动作的分值累加得到。特征表示方面，基于转移的方法可以充分利用已形成的子树信息，从而形成丰富的特征，以指导模型决策下一个动作。模型通过贪心搜索或者柱搜索等解码算法找到近似最优的依存树。和基于图的方法类似，基于转移的方法通常也采用在线训练算法学习特征权重。 3、多模型融合的依存句法分析方法基于图和基于转移的方法从不同的角度解决问题，各有优势。基于图的模型进行全局搜索但只能利用有限的子树特征，而基于转移的模型搜索空间有限但可以充分利用已构成的子树信息构成丰富的特征。详细比较发现，这两种方法存在不同的错误分布。因此，研究者们使用不同的方法融合两种模型的优势，常见的方法有：stacked learning；对多个模型的结果加权后重新解码(re-parsing)；从训练语料中多次抽样训练多个模型(bagging)。 二、短语结构句法分析短语结构句法分析的研究基于上下文无关文法（Context Free Grammar,CEG）。上下文无关文法可以定义为四元组&lt;T,N,S,R&gt;，其中T表示终结符的集合（即词的集合），N表示非终结符的集合（即文法标注和词性标记的集合），S表示充当句法树根节点的特殊非终结符，而 R 表示文法规则的集合，其中每条文法规则可以表示为 ，这里的 表示由非终结符与终结符组成的一个序列（允许为空）。 当前主流的句法分析模型，无论底层的机器学习方法（生成模型或者判别模型）或是所采用的系统框架（单系统、多系统融合或者两阶段的重排序方法），本质上都可以归到基于词汇化方法或者基于符号重标记方法的句法分析器。 三、深层文法句法分析相对前两种句法分析，深层文法句法分析的研究相对较少。本节简要介绍词汇化树邻接文法（Lexicalized Tree Adjoining Grammar， LTAG）、词汇功能文法（Lexical FunctionalGrammar， LFG）和组合范畴文法（Combinatory Categorial Grammar， CCG）。 1、词汇化树邻接文法，简称LTAG，是对树邻接文法（TAG）进行词汇化扩展得到的。 树邻接文法包含两种基本树（Elementary Tree）：初始树（Initial Tree）和辅助树（Auxiliary Tree）。 在树邻接文法中，有两种子树操作：替换（ Substitution）和插接（ Adjunction）。 词汇化语法是给所有基本树都和具体词关联起来，使得树更加具有个性化。 2、词汇功能文法，简称 LFG，是一种短语结构文法。 LFG 把语言看成是由多维结构组成的，每一维都用特殊规则、概念和格式表示成一个特殊结构。 LFG 包含两种最基本的结构： 1） F-结构，用于表示语法功能； 2） C-结构，用于表示句法功能。 除此之外还有一些其他结构，用于表示浅层信息，例如谓词论元关系等。 3、组合范畴文法，简称CCG，一种类型驱动的词汇化文法，通过词汇范畴显式地提供从句法到语义的接口，属于短语结构文法。 CCG 的基本操作包括： 1）原子范畴（Atomic Category），用于表达基本的词汇类别和句法功能； 2）组合范畴（Function Category），由原子范畴构成，通常用 X/Y 或 X\Y 来表示可以向左或者向右寻找变元 Y 来获得组合 X。 基于深层文法的句法分析器也取得一些进展。例如，Boullier 和 Sagot 构建基于LFG的分析器-SxLFG。 WenduanXu 等人借鉴依存分析模型，采用 Shift-reduce 框架构建高效的CCG 分析器取得很好的效果。在树库语料方面，大多数深层文法树库是通过从 PTB 自动转换得到的，而黄昌宁老师在清华中文树库基础上结合中文特点，探索如何构建中文 CCG 树库。 四、基于深度学习的句法分析深度学习（Deep Learning）在句法分析课题上主要研究工作集中在特征表示方面。深度学习把原子特征进行向量化，在利用多层神经元网络提取特征。所谓向量化就是把词、词性等用低维、连续实数空间上的向量来表示，从而便于寻找特征组合与表示，同时容易进行计算。 在图 1 中，把词、词性、类别标签等原子特征表示为向量，然后利用多层网络进行特征提取。深度学习在特征表示方面有如下优点： 1）只需要原子特征。这些原子特征以前是通过人工的自由组合形成最终的一元特征、二元特征、三元特征、四元特征甚至更多元的组合。这种人工组合最后取得较好的效果，但是事实上我们不知道怎么组合能形成最佳的特征集合。深度学习将所有的原子特征向量化之后，直接采用向量乘法以及非线性等各种运算从理论上能实现任意元的特征组合。 2）能使用更多的原子特征。比如基于图的模型中，在建立弧时，不仅仅使用左边第一个词、右边第一个词等原子特征，还可以使用左边整个词序列、右边整个词序列的特征。研究人员把这种基于深度学习的特征表示方法分别应用在基于图的句法分析模型和基于转移的句法分析模型上，实验结果表明深度学习方法开始在句法中发挥作用。]]></content>
      <categories>
        <category>NLP</category>
        <category>句法分析</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>Syntactically Annotating</tag>
        <tag>句法分析</tag>
        <tag>中文句法结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | 处理json文件]]></title>
    <url>%2F2018%2F06%2F21%2Fpython%E4%B9%8Bjson%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%2F</url>
    <content type="text"><![CDATA[Python | 处理json文件12345678910json文件内容： &#123; "stations":[ &#123; "sta_name":"北京北", "sta_ename":"beijingbei", "sta_code":"VAP", "text":"自三峡七百里中，两岸连山，略无阙处。", &#125;]&#125; 1. 需要加载一个Json文件，并将Json中的某些项进行修改，然后写回到一个新的Json文件中去。Model代码： 1python3.6]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Attention机制的理解]]></title>
    <url>%2F2018%2F06%2F12%2FAttention%E6%9C%BA%E5%88%B6%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Attention机制的理解Attention Model类似于人脑的注意力模型，说到底是一种资源分配模型，在某个特定时刻，你的注意力总是集中在画面中的某个焦点部分，而对其它部分视而不见。 |Encoder-Decoder框架文本处理领域的AM模型，因为目前绝大多数文献中出现的AM模型是附着在Encoder-Decoder框架下的，当然，其实AM模型可以看作一种通用的思想，本身并不依赖于Encoder-Decoder模型，这点需要注意。 Encoder-Decoder框架可以看作是一种文本处理领域的研究模式，应用场景异常广泛，下图是文本处理领域里常用的Encoder-Decoder框架最抽象的一种表示： Encoder-Decoder框架可以这么直观地去理解：可以把它看作适合处理由一个句子（或篇章）生成另外一个句子（或篇章）的通用处理模型。对于句子对&lt;X,Y&gt;，我们的目标是给定输入句子X，期待通过Encoder-Decoder框架来生成目标句子Y。X和Y可以是同一种语言，也可以是两种不同的语言。而X和Y分别由各自的单词序列构成： Encoder顾名思义就是对输入句子X进行编码，将输入句子通过非线性变换转化为中间语义表示C：对于解码器Decoder来说，其任务是根据句子X的中间语义表示C和之前已经生成的历史信息y1,y2….yi-1来生成i时刻要生成的单词yi ： Encoder-Decoder框架是个通用的计算机框架，可以有各种不同的模型结合，具体用什么模型由研究者自己决定，常见的比如CNN/RNN/BiRNN/GRU/LSTM/Deep LSTM 。 Attention Model图1中展示的Encoder-Decoder模型是没有体现出“注意力模型”的，所以可以把它看作是注意力不集中的分心模型。为什么说它注意力不集中呢？请观察下目标句子Y中每个单词的生成过程如下： 其中： f是decoder的非线性变换函数。由此可看出，在生成目标句子的单词时，不论生成哪个单词（y1,y2还是y3），他们使用的句子X的语义编码C都是一样的，没有任何区别。而语义编码C是由句子X的每个单词经过Encoder 编码产生的，这意味着不论是生成哪个单词，y1,y2还是y3，其实句子X中任意单词对生成某个目标单词yi来说影响力都是相同的，没有任何区别（其实如果Encoder是RNN的话，理论上越是后输入的单词影响越大，并非等权的，估计这也是为何Google提出Sequence to Sequence模型时发现把输入句子逆序输入做翻译效果会更好的小Trick的原因）。这就是为何说这个模型没有体现出注意力的缘由。这类似于你看到眼前的画面，但是没有注意焦点一样。如果拿机器翻译来解释这个分心模型的Encoder-Decoder框架更好理解，比如输入的是英文句子：Tom chase Jerry，Encoder-Decoder框架逐步生成中文单词：“汤姆”，“追逐”，“杰瑞”。在翻译“杰瑞”这个中文单词的时候，分心模型里面的每个英文单词对于翻译目标单词“杰瑞”贡献是相同的，很明显这里不太合理，显然“Jerry”对于翻译成“杰瑞”更重要，但是分心模型是无法体现这一点的，这就是为何说它没有引入注意力的原因。没有引入注意力的模型在输入句子比较短的时候估计问题不大，但是如果输入句子比较长，此时所有语义完全通过一个中间语义向量来表示，单词自身的信息已经消失，可想而知会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。 上面的例子中，如果引入AM模型的话，应该在翻译“杰瑞”的时候，体现出英文单词对于翻译当前中文单词不同的影响程度，比如给出类似下面一个概率分布值： （Tom,0.3）(Chase,0.2)(Jerry,0.5) 每个英文单词的概率代表了翻译当前单词“杰瑞”时，注意力分配模型分配给不同英文单词的注意力大小。这对于正确翻译目标语单词肯定是有帮助的，因为引入了新的信息。同理，目标句子中的每个单词都应该学会其对应的源语句子中单词的注意力分配概率信息。这意味着在生成每个单词Yi的时候，原先都是相同的中间语义表示C会替换成根据当前生成单词而不断变化的Ci。理解AM模型的关键就是这里，即由固定的中间语义表示C换成了根据当前输出单词来调整成加入注意力模型的变化的Ci。增加了AM模型的Encoder-Decoder框架理解起来如图2所示。即生成目标句子单词的过程成了下面的形式：]]></content>
      <categories>
        <category>DeepLearning</category>
        <category>Attention</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>Attention</tag>
        <tag>Encoder-Decoder</tag>
        <tag>Neural Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fast and Robust Neural Network Joint Models for Statistical Machine.md]]></title>
    <url>%2F2018%2F06%2F09%2FFast-and-Robust-Neural-Network-Joint-Models-for-Statistical-Machine-md%2F</url>
    <content type="text"><![CDATA[Fast and Robust Neural Network Joint Models for Statistical Machine TranslationNNJM:通过一个源上下文窗口扩展NNLM（which augments the NNJM with a source context window）。该模型是纯词汇化(purely lexicalized)的，可以集成到任何MT的Decoder中。具体来说，该模型利用m-word源窗口扩展一个n-gram目标语言模型。和以往的联合模型不同，该模型能够很容易作为一个feature被整合到任何SMT解码器中。 NNJM近似地估计了以源句子S为条件的目标假设T的概率。遵循目标的标准n-gram LM分解，其中每个目标字ti都受前面的n- 1个目标字的制约。为了使这个模型成为一个联合模型，对源上下文向量 进行了条件分析： 每一个目标词ti都直接对应着一个在位置ai的源词，是在以ai为中心的m-word的源窗口。 这种从属（affiliation）概念源自单词对齐，但与单词对齐不同，每个目标单词必须与一个非空(non-NULL)源单词相关联。 中文-英语平行句子的NNJM上下文模型例子如下图： 论文中采用的是n=4、m=11的15-gram LM 模型（神经网络语言模型能够优雅地扩展并利用任意大的上下文大小）。 论文中的神经网络结构与Bengio et.al等人的前溃神经网络语言模型结构基本相似，如下图。 1. NNJM中的神经网络结构NNJM中的神经网络架构与Bengio et al.(2003)所描述的原始前馈NNLM体系结构（feed-forward NNJM architecture）几乎相同。隐藏层大小、词汇表大小和源窗口大小选择了这些值: 2. 神经网络训练除了使用平行语料库代替单语语料库外，训练过程与NNLM相同。在形式上，我们寻求使训练数据的逻辑可能性最大化： * 优化（Optimization）: 带SGD的标准后向传播。 * 权重（Weights）：[-0.05,0.05]之间进行随机初始化 * 学习率： 10^-3 * minibatch size: 128 * 20,000 minibatches/each epoch, 计算验证集的可能性。 * 40 epochs * 我们在没有L2正则化或动量的情况下执行基本的权值更新。 * Training is performed on a single Tesla K10 GPU, with each epoch (128*20k = 2.6M samples) 3. Self-Normalized Neural NetworkNNLM的计算成本在解码中是一个重要的问题，并且这个成本由整个目标词汇表上的输出softmax所支配。我们的目标是能够使用相当大的且没有词类（word-classes）的词汇表，并且简单地避免在解码时计算整个输出层。为此，我们提出了自规一化（self-normalization）的新技术，其中输出层分数是接近于没有显示执行softmax的概率。我们所定义的标准softmax对数似然函数如下： 由上看出，在解码阶段当log(Z(x))等于0时（Z(x)=1）我们就只需要计算输出层的r行而不是计算整个矩阵，但是很难保证用这个来训练神经网络，所以可以通过增加训练目标函数来明确鼓励log-softmax正态化器（explicitly encourage the log-softmax normalizer）尽可能接近0： 在这种情况下，输出层的偏置权值初始化为log(1/|V|)，因此初始网络是自归一化的。在解码时，使用作为特征得分，而不是选用log(P(x))。在本篇论文中NNNJM结构中，在解码过程中，self-normalization将查找速度提高了15倍。 在用噪声对比估计（ Noise Contrastive Estimation ，NCE）训练自归一化的NNLMs时虽然加速了训练时间，但是没有机制能控制自归一化程度。 4. Pre-Computing the Hidden Layer自归一化显著提高了NNJM查找的速度，该模型仍比 back-off LM慢几个数量级。在这里，我们展示了预计算(Pre-Computing)第一个隐藏层的技巧，它进一步将NNJM查找速度提高了1000倍。请注意，这种技术只会导致自归一化，前向反馈，有一个隐藏层的NNLM-style网络的显著加速。 5. Decoding with the NNJM论文所提出的NNJM本质上是一个带有附加源上下文的n-gram NNLM，所以可以很容易地集成到任何SMT解码器中。 NNJM is fundamentally an n-gram NNLM with additional source context, it can easily be integrated into any SMT decoder。 主要介绍将NNJM集成到分层解码器时必须考虑的事项。 Hierarchical Parsing（分层句法分析） Affiliation Heuristic（加入启发式）]]></content>
      <categories>
        <category>Papers</category>
        <category>SMT</category>
      </categories>
      <tags>
        <tag>Papers</tag>
        <tag>论文阅读笔记</tag>
        <tag>GEC</tag>
        <tag>SMT</tag>
        <tag>NNJM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning with PyTorch(60 Minute)]]></title>
    <url>%2F2018%2F06%2F09%2FPytorch-Deep-Learning-with-PyTorch-A-60-Minute-Blitz%2F</url>
    <content type="text"><![CDATA[Deep Learning with PyTorch:A 60 Minute Blitz 一、PyTorch 是什么它是一个基于Python的科学计算包，目标用户有两类： 为了使用GPU来替代numpy。 一个深度学习援救平台：提供最大的灵活性和速度。 开始张量（Tensors)张量类似于Numpy的ndarrays，不同之处在于张量可以使用GPU来加快计算。 from __future__ import print_function import torch 构建一个未初始化的5*3的矩阵： x = torch.empty(5, 3) print(x) 构建一个随机初始化的矩阵： x = torch.rand(5, 3) print(x) 构建一个以零填充且数据类型为long的矩阵： x = torch.zeros(5, 3, dtype=torch.long) print(x) 直接从数据构造张量： x = torch.tensor([5.5, 3])print(x) 也可以根据现有张量创建张量。这些方法将重用输入张量的属性，例如dtype，除非用户提供了新的值： x = x.new_ones(5, 3, dtype=torch.double) #new_* methods 获取大小 print(x) x = torch.randn_like(x, dtype=torch.float) # 重写dtype print(x) # 结果具有相同的大小 获取张量大小： print(x.size()) 注意：torch.Size实际上是一个元组，所以它支持所有的元组操作。 操作（Operations）张量上的操作有多重语法形式，下面我们一加法为例进行讲解。 加法：语法1 print(&quot;x: &quot;, x) y = torch.rand(5, 3) print(x + y) 加法：语法2 print(&quot;x: &quot;, x) print(torch.add(x, y)) 加法：提供输出张量作为参数 result = torch.empty(5, 3) torch.add(x, y, out=result) print(result) 加法: in-place #adds x to y y.add_(x) print(y) 注意：任何使张量在原位发生变异的操作都是用， 例如: x.copy(y), x.t_(),都将会改变x。 可以任意使用标准Numpy-like索引： print(x) print(x[:, 1]) print(x[1, :]) print(x[2, 4]) 调整大小(Resizing)：如果您想调整大小/重塑张量，可以使用torch.view x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) print(x.size(), y.size(), z.size()) 如果有一个单元张量(a one element tensor)，请使用.item（）将该值作为Python数字来获取 x = torch.rand(1) print(x) print(x.item()) 这里描述了100+张量操作，包括转置，索引，切片，数学运算，线性代数，随机数等。 NumPy Bridge把一个torch张量转换为numpy数组或者反过来都是很简单的。 Torch张量和numpy数组将共享潜在的内存，改变其中一个也将改变另一个。 将Torch张量转换成一个NumPy数组 ： &gt;&gt;&gt; a = torch.ones(5) &gt;&gt;&gt; print(a) Out: tensor([ 1., 1., 1., 1., 1.]) &gt;&gt;&gt; b = a.numpy() &gt;&gt;&gt; print(b) Out: [1. 1. 1. 1. 1.] numpy数组的值如何在改变？ a.add_(1) print(a) print(b) 把NumPy数组转换成Torch张量：看看改变numpy数组如何自动改变torch张量。 import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) print(b) 所有在CPU上的张量，除了字符张量，都支持在numpy之间转换。 CUDA 张量使用 .to 函数可以将张量移动到GPU上。 # let us run this cell only if CUDA is available # We will use ``torch.device`` objects to move tensors in and out of GPU if torch.cuda.is_available(): device = torch.device(&quot;cuda&quot;) # a CUDA device object y = torch.ones_like(x, device=device) x = x.to(device) z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.double)) Out: tensor([ 0.5921], device=’cuda:0’)tensor([ 0.5921], dtype=torch.float64) Autograd: 自动求导（automatic differentiation）PyTorch中所有神经网络的核心是autograd包。我们首先简单介绍一下这个包,然后训练我们的第一个神经网络。 autograd包为张量上的所有操作提供了自动求导.它是一个运行时定义的框架,这意味着反向传播是根据你的代码如何运行来定义,并且每次迭代可以不同. 接下来我们用一些简单的示例来看这个包。 Tensortorch.Tensor是包的核心类，如果将其属性requires_grad设置为true,它开始跟踪它上面的所有操作。 当完成计算时可以调用.backward()并自动计算所有的梯度。该张量的梯度被计算放入搭配到.grad属性中。阻止跟踪历史的张量，可以通过调用.detch()将其从计算历史记录中分离出来，并防止跟踪将来的计算。为了防止跟踪历史记录（和使用内存），您还可以在 with torch.no_grad（）包装代码块。这在评估模型时特别有用，因为该模型可能具有requires_grad = True的可训练参数，但我们不需要梯度。 对自动求导的实现还有一个非常重要的类,即函数(Function) 张量（Tensor）和函数(Function)是相互联系的,并形成一个非循环图来构建一个完整的计算过程.每个变量有一个.grad_fn属性,它指向创建该变量的一个Function(用户自己创建的变量除外,它的grad_fn属性为None)。 如果你想计算导数,可以在一个张量上调用.backward().如果一个Tensor是一个标量(它只有一个元素值),你不必给backward()指定任何的参数,但是该Variable有多个值,你需要指定一个和该张量相同形状的的gradient参数(查看API发现实际为gradients参数)。 import torch # 创建一个张量，饼设置reuqires_grad=True来跟踪计算过程 x = torch.ones(2, 2, reuqires_grad=True) print(x) Out: tensor([[ 1., 1.], [ 1., 1.]]) 在张量上执行操作: y = x + 2 print(y) Out: tensor([[ 3., 3.], [ 3., 3.]]) 因为y是通过一个操作创建的,所以它有grad_fn,而x是由用户创建,所以它的grad_fn为None. print(y.grad_fn) Out: &lt;AddBackward0 object at 0x0000020D2A5CC048&gt; 在张量y上执行更多操作： z = y * y * 3 out = z.mean() print(&quot;z : &quot;, z, &quot;, out: &quot;, out) Out: z : tensor([[ 27., 27.], [ 27., 27.]]) , out: tensor(27.) .requires_grad_（…）按位（in-place）更改现有张量的requires_grad标志。如果没有给出，输入标志默认为True。 a = torch.randn(2, 2) a = ((a * 3) / (a - 0)) print(a.requires_grad) a.requires_grad_(True) print(a.requires_grad) b = (a * a).sum() print(b.grad_fn) 梯度现在我们来执行反向传播,因为out包含一个标量,out.backward()相当于执行out.backward(torch.tensor(1)): out.backward() # 输出out对x的梯度d(out)/d(x): print(&quot;x.grad: &quot;, x.grad) 输出： 你应该得到一个值全为4.5的矩阵，我们把out称为张量O。则 我们还可以用自动求导做更多有趣的事： x = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm() &lt; 1000: y = y * 2 print(y) 输出： gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)y.backward(gradients) print(x.grad) 还可以通过使用torch.no_grad（）包装代码块来停止autograd跟踪在张量上的历史记录，其中require_grad = True： print(x.requires_grad) print((x ** 2).requires_grad) with torch.no_grad(): print((x ** 2 ).requires_grad) 输出： Documentation of autograd and Function is at http://pytorch.org/docs/autograd 神经网络（Neural Networks）可以使用torch.nn包来构建神经网络。我们已知道autograd包,nn包依赖autograd包来定义模型并求导.一个nn.Module包含各个层和一个faward(input)方法,该方法返回output。 例如,我们来看一下下面这个分类数字图像的网络。convnet 这是一个简单的前溃神经网络，它接受一个输入，然后一层接着一层的输入，直到最后得到结果。 神经网络的典型训练过程如下： 定义神经网络模型。它有一些可学习的参数（或者权重）； 在输入数据集上迭代 通过神经网络处理输入，主要体现在网络的前向传播; 计算损失（输出结果和正确值的差距大小） 将梯度反向传播回网络的参数，反向传播求梯度。 根据梯度值更新网络的参数，主要使用如下简单的更新原则： weight = weight - learning_rate * gradient 定义网络Let’s define this network: import torch import torch.nn as nn import torch.nn.functional as F Class Net(nn.Module): def __init__(self): # super就是在子类中调用父类方法时用的。 super(Net, self).__init__() # 对继承自父类的属性进行初始化。而且是用父类的初始化方法来初始化继承的属性。也就是说，子类继承了父类的所有属性和方法，父类属性自然会用父类方法来进行初始化。当然，如果初始化的逻辑与父类的不同，不使用父类的方法，自己重新初始化也是可以的。 # 1 input image channel, 6 output channels, 5*5 square convution # kernel self.comv1 = nn.Conv2d(1, 6, 5) self.comv2 = nn.Conv2d(6, 16, 5) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x),(2, 2)) # if the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x), 2) x = view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) 输出： learn more about the network：在pytorch中只需要定义forward函数即可，backward函数会在使用autograd时自动创建（其中梯度是计算过的）。可以在forward函数中使用Tensor的任何操作。 net.aprameters()会返回模型中可学习的参数。 params = list(net.parameters()) print(&apos;可学习参数的个数：&apos;, len(params)) #print(&quot;可学习的参数：&quot;, params) print(params[0].size()) # conv1&apos;s的权值 for param in params: print(param.size()) 以上代码段实现将该神经网络的可学习参数都放到params中,并且输出了第一层conv的参数大小.输出： 注意：我们来尝试一个3232的随机输入，这个网络（LeNet）期望的输入大小是3232。如果使用的是MINIST数据集来训练这个网络，请把数据集中图片大小调整到32*32。 input = torch.randn（1，1，32，32） print(&quot;input: &quot;, input) out = net(input) print(&quot;out: &quot;, out) 输出： 把所有参数的梯度缓存区清零，然后进行随机梯度的的反向传播。 net.zero_grad() out.backward(torch.randn(1, 10)) Note: torch.nn只支持小批量输入（mini-batches）。整个torch.nn包仅支持作为最小样本量的输入，而不支持单个样本。 例如，nn.Conv2d只接受一个四维张量（nSamples nChannels Height Width），即样本数通道数高度宽度。 如果你有单个样本,只需使用input.unsqueeze(0)来添加一个虚假的批量维度. 在继续之前,我们回顾一下到目前为止见过的所有类。 回顾: torch.Tensor - 一个支持autograd等操作（比如banckward()）的多维数组，也支持梯度w、r、t等张量。 nn.Module - 神经网络模块。封装参数的便捷方式，移动到GPU运行，导出，加载等。 nn.Parameters - 一种张量，当作为属性赋值给一个模块（Module）时,能被自动注册为一个参数。 autograd.Function - 实现一个自动求导操作的前向和反向定义,每个张量操作至少创建一个函数节点，该节点连接到创建Tensor并对其历史进行编码的函数。 以上内容： 定义一个神经网络 处理输入和调用backward 剩下的内容: 计算损失值 更新神经网络的权值 损失函数（Loss Function）一个损失函数接受一对（output， target）作为输入(output为网络的输出,target为实际值),，计算一个值来评估网络的输出和目标值（实际值）相差多少。 在nn包中有几种不同的损失函数。一个简单的损失函数是:nn.MSELoss,它计算的是网络的输出和目标值之间的均方误差。 例如： output = net(input) target = torch.arrange(1, 11) # 例如，虚拟目标 target = target.view(1, -1)# 使其与输出(output)形状相同 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) 输出： 现在，如果反向跟踪loss,用它的属性.grad_fn，你会的到下面这样的一个计算图： 所以, 当调用loss.backward(),整个图与w、r、t的损失不同,图中所有变量（其requres_grad=True）将拥有.grad变量来累计他们的梯度. 为了说明,我们反向跟踪几步: print(loss.grad_fn) # MSELoss print(loss.grad_fn.next_functions[0][0]) # Linear print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU 输出： 反向传播（Backprop）为了反向传播误差,我们所需做的是调用loss.backward().你需要清除已存在的梯度,否则梯度将被累加到已存在的梯度。 现在，我们将调用loss.backward(),并查看conv1层的偏置项在反向传播前后的梯度。 net.zero_grad()# zeroes the gradient buffers of all parameters print(&apos;conv1.bias.grad before backward&apos;) print(net.conv1.bias.grad) loss.backward() print(&apos;conv1.bias.grad after backward&apos;) print(net.conv1.bias.grad) 输出： 现在我们也知道了如何使用损失函数。 神经网络包包含各种深度神经网络的构建模块和损失函数。完整的文档列表在这里。 接下来是更新权重。 更新权重最简单的更新权重的方法是：随机梯度下降（SGD）。 weight = weight - learning_rate * gradient 可以通过以下代码实现梯度更新： learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) 当使用神经网络时，有几种不同的权重更新方法，例如有SGD,Nesterov-SGD,Adam,RMSProp等。为了能够更好地使用这些方法，Pytorch提供了一个小工具包：torch.optim来实现上述所说的更新方法。使用起来也很简单，代码如下： import torch.optim as optim # create your optimizer optimizer = optim.SGD(net.parameters(), lr=0.01) # in your training loop: optimizer.zero_grad() # zero the gradient buffers output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # Does the update 训练分类器（Training a classifier）What about Data?一般来说，在处理图像、文本、音频或者视频数据时可以使用标准的python包把数据加载成一个numpy数组， 然后再把这个数组转换成一个 torch.*Tensor。 对于图像来说，可以使用Pillow、OpenCV等包。 对于音频来说，可以使用scipy和librosa包。 对于文本来说，无论是原始的Python还是基于Cython的加载，或者NLTK和SpaCy都是有用的 特别是对于视觉，我们已经创建了一个名为torchvision的软件包，它具有常用数据集的数据加载器，如Imagenet，CIFAR10，MNIST等，以及图像数据转换器，即torchvision.datasets 和 torch.utils.data.DataLoader。 这提供了巨大的便利并避免了编写样板代码。 本例中我们将使用CIFAR-10数据集。它有以下几类： ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。在CIFAR-10数据集中的数据大小是33232，例如尺寸为32x32像素的3通道彩色图像。 训练一个图像分类器 使用torchvision加载并归一化（normalizing）CIFAR10训练和测试数据集。 定义一个卷积神经网络 定义一个损失函数 在训练集上训练网络 在测试集上测试数据 加载和归一化CIFAR10 torchvison能够很简单的加载CIFAR10。 import torch import torchvision import torchvision.transforms as transforms torchvision数集的输出是范围为[0, 1]的PILImage图像。我们将其转换为归一化范围[-1, 1]的张量。 transform = transform.Compose([transform])]]></content>
      <categories>
        <category>Pytorch</category>
        <category>Tutorials</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Adapting Grammatical Error Correction Based on the Native Language of Writers with Neural Network Joint Models]]></title>
    <url>%2F2018%2F06%2F04%2FAdapting-Grammatical-Error-Correction-Based-on-the-Native-Language-of-Writers-with-Neural-Network-Joint-Models%2F</url>
    <content type="text"><![CDATA[Adapting Grammatical Error Correction Based on the Native Language of Writers with Neural Network Joint Models本篇论文： 采用一个使用L1-specific学习者文本的NNJM（神经网络联合模型），并把它作为一个feature整合到一个基于GEC的统计机器翻译系统（解码器）中。本文的两点贡献： 这是第一个使用SMT方法并覆盖所有错误类型的工作来对GEC执行基于L1的自适应 我们引入了一种新的NNJM适应方法，并证明该方法可以处理比一般域数据小得多的域内数据。 适应（Adaptation）是通过使用训练在一般域数据上的未适应的NNJM来完成的。使用自归一化的对数似然目标函数作为起点，使用较小的L1-specific的域内数据进行后续迭代训练，并使用包含Kullback-Leibler (KL)离散正则项的修正目标函数。 摘要尽管第一语言(The Native Language,L1)对第二语言(The Second Language,L2)的写作有显著的影响，但是基于作者母语（L1)的适应（Adaptation）是 语法纠错(GEC)任务仍未充分探索的一个重要方面。本文采用神经网络联合模型(神经网络联合模型,NNJM)，使用L1-specific的学习者文本，将其集成到基于统计机器翻译(SMT)的GEC系统中。具体地说，我们针对一般学习者文本(general learner text，不是L1-specific的)训练NNJM，然后再使用Kullback-Leibler divergence正则化目标函数训练L1-specific的数据，以保持模型的泛化。我们将这个调整后的NNJM作为一个基于SMT的英语GEC系统的功能，并表明该系统在L1中文、俄语和西班牙语作者的英语文本上获得了显著的F0.5。 为什么考虑 L1-specific 学习者文本？主要是L1背景不同，学习第二语言时有不同的影响，也就是L1和L2之间的跨语言影响。 芬兰的英语学习者：过度概括了介词‘in’的使用。 例如：“When they had escaped in the police car they sat under the tree.”这个句子中的介词&quot;in&quot; 应该为 “from” 。 中国的英语学习者：由于汉语中没有动词形态变化，所以在书写英语时经常会出现动词时态和动词形式错误。 第一语言对第二语言写作的跨语言影响是一个非常复杂的现象，学习者所犯的错误不能直接归因于两种语言的相似或不同。 学习者似乎遵循着两个互补的原则（Ortega 2009）:第一语言中起作用的可能在第二语言中起作用，因为人类语言基本上是相似的;但如果听起来太像L1，那么在L2中可能就行不通了。 因此本文采用数据驱动（data-driven）的方法对这些影响因素进行建模,并使用具有相同L1背景的作者撰写的L2文本对GEC系统进行调整。 Why SMT ?GEC中两个最常用的方法是：分类方法（the classification approach）和 统计机器翻译方法（the statistical machine translation approach）。 SMT的优势： SMT方法把不合语法的文本转换成格式良好的文本的学习文本转换的能力，使得它能够纠正各种各样的错误，包括复杂的错误，而这些错误是很难用分类方法（the classification approach）处理的，这也使得SMT成为GEC的流行范例。 SMT方法并不用于专门的错误类型建模，也不需要像解析（parsing）和词性标注(POS tagging)这样的语言分析。 NNJM –&gt; Neural Network Joint Model关于NNJM在论文Fast and Robust Neural Network Joint Models for Statistical MachineTranslation（Devlin et al.,2014） NNJM:通过一个源上下文窗口扩展NNLM（which augments the NNJM with a source context window）。该模型是纯词汇化(purely lexicalized)的，可以集成到任何MT的Decoder中。具体来说，该模型利用m-word源窗口扩展一个n-gram目标语言模型。和以往的联合模型不同，该模型能够很容易作为一个feature被整合到任何SMT解码器中。 NNJM近似地估计了以源句子S为条件的目标假设T的概率。遵循目标的标准n-gram LM分解，其中每个目标字ti都受前面的n- 1个目标字的制约。为了使这个模型成为一个联合模型，对源上下文向量 进行了条件分析： 每一个目标词ti都直接对应着一个在位置ai的源词，是在以ai为中心的m-word的源窗口。 这种从属（affiliation）概念源自单词对齐，但与单词对齐不同，每个目标单词必须与一个非空(non-NULL)源单词相关联。 中文-英语平行句子的NNJM上下文模型例子如下图： 论文中采用的是n=4、m=11的15-gram LM 模型（神经网络语言模型能够优雅地扩展并利用任意大的上下文大小）。论文中的神经网络结构与Bengio et.al等人的前溃神经网络语言模型结构基本相似，如下图。 NNJM中的神经网络结构NNJM中的神经网络架构与Bengio et al.(2003)所描述的原始前馈NNLM体系结构（feed-forward NNJM architecture）几乎相同。隐藏层大小、词汇表大小和源窗口大小选择了这些值: 由于NNJM使用的是一个固定窗口的上下文，所以很容易将其整合到SMT解码器框架中，实验结果也证明了这样提升了SMT-based GEC的性能。 A MT Framework For GEC本文中将GEC视为从一个可能错误的输入句子到一个纠正句子的翻译过程。框架设计细节： 采用一个基于短语的SMT系统–Moses框架,它主要是通过一个对数线性模型来找到最佳假设 T*： SMT中两个主要部分：翻译模型(TM)和语言模型（LM）。 TM: 主要负责生成假设T（通常是短语表），使用并行数据（即，学习者写入的句子（源数据）及其相应的校正句子（目标数据））进行训练。还使用正向和反向短语翻译概率和词汇权重等特征对假设进行评分，从而选出最佳假设T*。 LM: 在格式良好的文本上进行驯良从而保证输出的流畅性。用MERT计算特征权重，用开发集优化度量。 由于NNJM有依赖于固定上下文的前馈结构，所以很容易将其作为一个feature整合到SMT解码器框架中。特征值由logP(T|S)给出，这个logP(T|S)是给出上下文的假设T中每个单词的对数概率总和。 上下文hi由n-1个之前的目标词和围绕与目标词ti对齐的源词的m个源词组成。 神经网络输出层的每个维度(Chollampatt et al.， 2016)给出了给定上下文h的输出词汇表中单词t出现的概率。 神经网络中的参数包括权值、偏差和嵌入矩阵都是用带随机梯度下降反向传播进行训练，损失函数使用的是与Devlin等所用(2014)相似的自归一项的对数似然目标函数。 KL Divergence Regularized Adaptation in-domain data： 由L1-specific的作者所写的错误文本及其相应的修正文本组成。 这种自适应训练是使用具有正则化项K的修正目标函数来完成的，该函数用于最小化pGD(y|h)与网络输出概率分布p(y|h)之间的KL离散度。 K将防止训练期间估计的概率分布偏离通用域NNJM的分布。 最终的自适应步骤的目标函数是L和K中的项的线性组合。 数据和评价训练数据处理和来源：来源： 新加坡国立大学学生英语语料库（the NUSCorpus of Learner English (NUCLE) (Dahlmeieret al., 2013)） Lang-8学习者语料库（the Lang-8 Learner Corpora v2(Mizumoto et al., 2011)），Lang-8提取的是只学习英语的学习者的文本。 处理： 用语言识别工具langid.py（https://github.com/saffsd/langid.py）来获取纯净的英语句子 删除Lang-8中的噪声源-目标句子对（ noisy sourcetarget sentence pairs），即其中源句子和目标句子长度的比率在[0.5,2.0]之外的句子对，或者它们的单词重叠比率小于0.2的句子对。 删除NUCLE和Lang-8中源句子或目标句子超过80个单词的句子对。 预处理后训练数据的统计见Table1： 基于Lang-8中提供的L1信息获取的自适应L1-specific 域内信息。 每一个L1，它的域外数据是由除L1-specific域内数据在外的联合训练数据（CONCAT）中获取的。 开发测试集从公共可用的 CLC-FCE 语料库中获取。FCE语料库包含由1,244位不同候选人在1,2000年和2001年参加剑桥ESOL英语第一证书（FCE）考试所写的1,244个脚本。根据脚本数量分成数量大致相等的两部分作为开发集和测试集。 Evaluation 实验结果Baseline SMT-based GEC sysytem用Moses(Version 3)构建所有基于SMT的GEC系统。 NNJM Adaptation :用全部的训练数据训练10个epoch。源上下文窗口大小设置为5，目标上下文窗口大小设置为4，形成一个(5+5)-gram的联合模型。使用一个mini-batch大小为128、学习率为0.1的随机梯度下降（SGD）进行训练。 Comparison to Other Adaptation TechniquesEffect of Adaptation Data关于正则化的影响 Evaluation on Benchmark Dataset 讨论和错误分析 相关工作 HOO(Helping Our Own)和 CoNll共享任务 使得GEC变得普及流行。 GEC已发表的相关工作旨在构建针对具体错误类型分类器和基于规则的系统，并将其结合构建成混合系统（hybrid systems）。 L1和L2间的跨语言影响主要用于母语识别任务，还用于类型学预测和ESL数据的预测误差分布。 最近，针对GEC提出了端对端（end-to-end）神经机器翻译框架，显示出了具有竞争力的结果。 本文中利用SMT方法和神经网络联合模型的优点，将基于L1背景的作者的NNJM模型整合到SMT框架中。通过KL离散正则化自适应来避免在较小的域内数据中的过拟合。 SMT中其它调节技术包括混合建模（mixture modeling）和可选的解码路径（alternative decoding paths）。]]></content>
      <categories>
        <category>Papers</category>
        <category>GEC</category>
      </categories>
      <tags>
        <tag>Papers</tag>
        <tag>论文阅读笔记</tag>
        <tag>GEC</tag>
        <tag>NNJM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之argparse使用]]></title>
    <url>%2F2018%2F05%2F09%2FPython%E4%B9%8Bargparse%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Python 命令行解析工具Argparse的介绍及使用Argparse Tutorial:smile:argparse是python的命令行解析工具，是Python标准库推荐使用的命令行参数解析模块，负责从sys.argv中解析程序所需的参数，同时argparse还可以自动生成帮助信息和错误提示。 Example以下代码是一个Python程序，它采用整数列表并生成总和或最大值: 假设上面的Python代码保存在名为argparse_tu1.py的文件中, 它可以在命令行运行，并提供有用的帮助消息: 当使用适当的参数运行时，它将输出命令行整数的和或最大值: python argparse_tu1.py 5 6 7 8 --sum 如果传入无效的参数，它将发出一个错误: python argparse_tu1.py x i a o 以下部分将引导完成此示例: 创建一个parser使用argparse的第一步就是创建一个ArgumentParser对象： &gt;&gt;&gt; parser = argparse.ArgumentParser(description &apos;Process some integers.&apos;) 创建的ArgumentParser对象保存了将命令行参数解析为Python数据类型的所需要的所有信息。 添加参数创建ArgumentParser对象之后，需要向其声明指定程序所需的参数信息（几个参数、是否必须、参数类型等等），这一步需要调用add_argument()方法实现。add_argument()方法会告诉ArgumentParser对象如何在命令行上获取字符串（注意：所有的命令行参数都是string类型）并将它们转换为程序所需的对象。调用parse_args（）时会存储和使用此信息。例如： 12parser.add_argument(&apos;integers&apos;, metavar=&apos;N&apos;, type=int, nargs=&apos;+&apos;, help=&apos;an integer for the accumulator&apos;)parser.add_argument(&apos;--sum&apos;, dest=&apos;accumulator&apos;, action=&apos;store_const&apos;, const=sum, default=max, help=&apos;sum the integers(default: find the max)&apos;) 参考：https://docs.python.org/3/library/argparse.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Argparse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | 对象和类]]></title>
    <url>%2F2018%2F05%2F01%2FPython%E4%B9%8B%E5%AF%B9%E8%B1%A1%E5%92%8C%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[Python之对象和类1. 什么是对象 2. 使用class定义类如果把类比作塑料盒子，类则像是制作和自用的模具。例如，Python的内置类String可以创建像‘cat’和‘duck’这样的字符串对象。Python中还有许多用来创建其他标准数据类型的类，包括字典、列表等。如果想要在Python中创建属于自己的对象，首先必须用关键词class来定义一个类。 1234567#创建一个空类class Person(): pass # 通过类名创建对象，同调用函数一样： someone = Person() (以上例子中，Person()创建了一个Person类的对象，并给它赋值someone这个名字。但是由于Person类是空的，所以由它创建的对象someone实际上什么也做不了。) 重新定义类，将Python中特殊的对象初始化方法init放入其中： 12345678class Person(): def __init__(self，name): #实际的Python类的定义形式。 __init__()是Python中一个特殊的函数名，用于根据类的定义创建实例对象。self参数指向了这个正在被创建的对象本身。当你在类声明里定义__init__()方法时，第一个参数必须为self。尽管self并不是一个Python保留字，但它很常用。 # 在初始化方法中添加name参数 self.name = name #用Person类创建一个对象，为name特性传递一个字符串参数。 hunter = Person("Elmer Fudd") print(&quot;The mighty hunter:&quot;, hunter.name) The mighty hunter: Elmer Fudd 3. 继承 12345678910class Car(): passclass Yugo(Car): pass #接着，为每个类创建一个实例对象: give_me_a_car = Car() give_me_a_yugo = Yugo() 123456class Car(): def exclaim(self): print("I'm a Car!")class Yugo(Car): pass # 最后，为每个类创建一个对象，并调用刚刚声明的exclaim方法： &gt;&gt;&gt; give_me_a_car = Car() &gt;&gt;&gt; give_me_a_yugo = Yugo() &gt;&gt;&gt; give_me_a_car.exclaim() I&apos;m a Car! &gt;&gt;&gt; give_me_a_yugo.exclaim() I&apos;m a Car! 我们不需要做任何特殊的操作，Yugo就自动从Car那里继承了exclaim()方法。但事实上，我们并不希望Yugo在exclaim()方法里宣称它是一个Car，这可能会造成身份危机（无法区分Car和Yugo）。让我们来看看怎么解决这个问题。 4. 覆盖方法新创建的子类会自动继承父类的所有信息。那子类是如何替代–或者说覆盖（override）–父类的方法。Yugo和Car一定存在着某些区别，不然的话，创建它又有什么意义？ 尝试改写以下Yugo中的exclaim()方法的功能： 123456789101112class Car(): def exclaim(self): print("I'm a Car!")class Yugo(Car): def exclaim(self): print("I'm a Yugo! Much like a Car , but more Yugo-ish.") #接着，为每个类创建一个实例对象: give_me_a_car = Car() give_me_a_yugo = Yugo() 看看它们各自会宣称什么? &gt;&gt;&gt; give_me_a_car.exclaim() I&apos;m a Car! &gt;&gt;&gt; give_me_a_yugo.exclaim() I&apos;m a Yugo! Much like a Car , but more Yugo-ish. 在上面的例子中，覆盖了父类的exclaim（）方法，在子类中，可以覆盖任何父类的方法，包括init()。下面的例子使用了之前创建过的Person类。我们来创建两个子类，分别代表医生（MDPerson）和律师（JDPerson）： class Person(): def __init__(self，name): self.name = name class MDPerson(Person): def __init__(self，name): self.name = &quot;Doctor&quot; + name class JDPerson(Person): def __init__(self，name): self.name = name + &quot;Esquire&quot; 在上面的例子中，子类的初始化方法init()接收的参数和父类Person一样，但存储到对象内部name特性的值却不尽相同： &gt;&gt;&gt; person = Person(&quot;Fudd&quot;) &gt;&gt;&gt; doctor = MDPerson(&quot;Fudd&quot;) &gt;&gt;&gt; lawyer = JDPerson(&quot;Fudd&quot;) &gt;&gt;&gt; print(person.name) Fudd &gt;&gt;&gt; print(doctor.name) Doctor Fudd &gt;&gt;&gt; print(lawyer.name) Fudd Esquire 5. 添加新方法 6. 使用super从父类得到帮助调用父类的方法—-&gt; super() 下面这个例子将定义一个新的类EmailPerson,用于表示有电子邮箱的Person。首先，来定义熟悉的Person类： class Person(): def __init__(self，name): self.name = name 下面是子类的定义，注意，子类的初始化方法init()中添加了一个额外的email参数： class EmailPerson(Person): def __init__(self，name, email): super().__init__(name) self.email = email 7. self的自辩Python中必须把self设置为实例方法（前面例子中你见到的所有方法都是实例方法）的第一个参数。 Python使用self参数来找到正确的对象所包含的特性和方法。通过下面的例子，来查看调用对象方法背后Python实际做的工作。 前面例子中所讲的Car类，再次调用exclaim()方法： &gt;&gt;&gt; car = Car() &gt;&gt;&gt; car.exclaim() I&apos;m a Car! 没看完，后续补充 8.9.10.11.12.13.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>对象</tag>
        <tag>类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keras实现CRF层遇到的问题：3D张量的报错]]></title>
    <url>%2F2018%2F04%2F25%2Fkeras%E5%AE%9E%E7%8E%B0CRF%E5%B1%82%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9A3D%E5%BC%A0%E9%87%8F%E7%9A%84%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[keras实现CRF层遇到的问题：3D张量的报错问题：在使用CRF层构建模型进行训练时，总是报错： 下面是ValueError的完整信息： ValueError: Index out of range using input dim 2; input has only 2 dims for &apos;loss/crf_1_loss/strided_slice&apos; (op: &apos;StridedSlice&apos;) with input shapes: [?,?], [3], [3], [3] and with computed input tensors: input[3] = &lt;1 1 1&gt;. 是张量的shape问题。具体的原因还需要进一步查找，先标记下，五一假后解决。]]></content>
      <categories>
        <category>Keras</category>
        <category>CodingErrors</category>
      </categories>
      <tags>
        <tag>Keras</tag>
        <tag>CodingErrors</tag>
        <tag>CRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[softmax() got an unexpected keyword argument 'axis']]></title>
    <url>%2F2018%2F04%2F25%2FKeras%E4%B9%8Bsoftmax-got-an-unexpected-keyword-argument-axis%2F</url>
    <content type="text"><![CDATA[softmax() got an unexpected keyword argument ‘axis’在使用keras构建模型时出现了以下错误： 根据错误位置提示的最后一行 可以知道是在tensoflow_backend.py中出现错误，如下图： 解决方法：把 return tf.nn.softmax(x, axis=axis) 改为： return tf.nn.softmax(x,axis) 简单粗暴好用的办法！感谢 TypeError: concat() got an unexpected keyword argument ‘axis’ 提供参考意见。 ps: 遇到狐假虎威的狼外婆和心怀险恶的小红帽，鲁智深是解决不了的，但是曹操自己能做到~]]></content>
      <categories>
        <category>Keras</category>
        <category>CodingErrors</category>
      </categories>
      <tags>
        <tag>Keras</tag>
        <tag>CodingErrors</tag>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序列标注与BIO标注]]></title>
    <url>%2F2018%2F04%2F24%2F%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%B8%8EBIO%E6%A0%87%E6%B3%A8%2F</url>
    <content type="text"><![CDATA[序列标注与BIO标注re: 参考博客 序列标注序列标注（Sequence labeling）是我们在解决NLP问题时经常遇到的基本问题之一。在序列标注中，我们想对一个序列的每一个元素标注一个标签。一般来说，一个序列指的是一个句子，而一个元素指的是句子中的一个词。比如信息提取问题可以认为是一个序列标注问题，如提取出会议时间、地点等。 序列标注一般可以分为两类： 1、原始标注（Raw labeling）：每个元素都需要被标注为一个标签。 2、联合标注（Joint segmentation and labeling）：所有的分段被标注为同样的标签。 命名实体识别（Named entity recognition， NER）是信息提取问题的一个子任务，需要将元素进行定位和分类，如人名、组织名、地点、时间、质量等。 举个NER和联合标注的例子。一个句子为：Yesterday , George Bush gave a speech. 其中包括一个命名实体：George Bush。我们希望将标签“人名”标注到整个短语“George Bush”中，而不是将两个词分别标注。这就是联合标注。]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>序列标注</tag>
        <tag>Sequence Labeling</tag>
        <tag>BIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络常用激活函数：Sigmoid与Softmax的对比]]></title>
    <url>%2F2018%2F04%2F08%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%9ASigmoid%E4%B8%8ESoftmax%E7%9A%84%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[神经网络常用激活函数：Sigmoid与Softmax的对比re1:https://yq.aliyun.com/articles/73661re2:https://www.cnblogs.com/harvey888/p/7087129.htmlre3:https://www.cnblogs.com/maybe2030/p/5678387.html?utm_source=tuicool&amp;utm_medium=referral 在逻辑回归模型中会使用计算出的概率来预测目标类别，经常用到的两个函数是Softmax和Sigmoid函数。从函数水平（帮助预测目标类别）上来看，这两个函数是相同的，但存在许多明显的数学差异，应用在深度学习和其他领域中，发挥了至关重要的作用。 Softmax函数Softmax函数计算事件超过’n’个不同事件的概率分布。一般来说，这个函数将会计算每个目标类别在所有可能的目标类中的概率。计算出的概率将有助于确定给定输入的目标类别。使用Softmax的主要优点是输出概率的范围，范围为0到1，所有概率的和将等于1。如果将softmax函数用于多分类模型，它会返回每个类别的概率，并且目标类别的概率值会很大。指数公式计算给定输入值的指数和输入中所有值的指数值之和。那么输入值的指数与指数值之和的比值就是softmax函数的输出。 Sigmoid函数Sigmoid计算事件属于不同类别的概率，但是概率和不一定等于1。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | 面向对象编程]]></title>
    <url>%2F2018%2F03%2F31%2Fpython%E4%B8%AD%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[python中的面向对象编程面向对象编程——Object Oriented Programming，简称OOP，是一种程序设计思想。OOP把对象作为程序的基本单元，一个对象包含了数据和操作数据的函数。 面向过程的程序设计把计算机程序视为一系列的命令集合，即一组函数的顺序执行。为了简化程序设计，面向过程把函数继续切分为子函数，即把大块函数通过切割成小块函数来降低系统的复杂度。 而面向对象的程序设计把计算机程序视为一组对象的集合，而每个对象都可以接收其他对象发过来的消息，并处理这些消息，计算机程序的执行就是一系列消息在各个对象之间传递。 一. Class(类)在 Python 中，所有数据类型都可以视为对象,当然也可以自定义对象，自定义的对象数据类型就是面向对象中的类(Class)。object表示该类是从哪个类继承下来的，如果没有合适的继承类，就使用 object 类，这是所有类最终都会继承的类。 1. 定义一个类]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>类</tag>
        <tag>OPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3-25-3-31学习计划]]></title>
    <url>%2F2018%2F03%2F25%2F2018%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[2018 学习计划 3.25-3.31学习计划 学习tensorflow 实现bilstm+crf模型 seq2seq+Attention 机制模型详解 4月18-4月23日 学习计划 18日 - 19日：调代码，CGED的position阶段，读论文 20日 - 21日：调代码，复现《A Nested Attention Neural Hybrid Model for Grammatical Error》实验。Correction 22日：参加中文信息学会沙龙-CGED，下午整理笔记，调试代码。整理一篇关于多分类多标签任务的博客(尽量)。 23日：调代码，看论文。今天公布CGED测试数据………………………….. 下周见]]></content>
      <categories>
        <category>学习计划</category>
      </categories>
      <tags>
        <tag>学习计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras之BiLSTM+CRF实现语法错误判断出现shape不符合问题]]></title>
    <url>%2F2018%2F03%2F23%2Fkeras%E4%B9%8BBiLSTM-CRF%E5%AE%9E%E7%8E%B0%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF%E5%88%A4%E6%96%AD%E5%87%BA%E7%8E%B0shape%E4%B8%8D%E7%AC%A6%E5%90%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[keras之BiLSTM+CRF实现语法错误判断出现shape不符合问题在用keras构建BiLSTM+CRF模型实现汉语语法错误诊断过程中，进行训练的时候总是报错： ValueError: Cannot feed value of shape (128, 1) for Tensor u&apos;crf_1_target:0&apos;, which has shape &apos;(?,?,?) 出现错误位置在： #bilstm layer bilstm_layer = Bidirectional(LSTM(hidden_dim, return_sequences=False)) model.add(bilstm_layer) print(&apos;bilstm_layer.input_shape:&apos;, bilstm_layer.input_shape) print(&apos;bilstm_layer.output_shape:&apos;, bilstm_layer.output_shape) drop_layer = Dropout(dropout_rate) model.add(drop_layer) dense = Dense(num_class) model.add(dense) print(&apos;drop_layer.input_shape:&apos;, drop_layer.input_shape) print(&apos;drop_layer.output_shape:&apos;, drop_layer.output_shape) time_layer = TimeDistributed(Dense(num_class)) model.add(time_layer) print(&apos;time_layer.input_shape:&apos;, time_layer.input_shape) print(&apos;time_layer.output_shape:&apos;, time_layer.output_shape) #加载CRF层 crf_layer = CRF(num_class, sparse_target=True) model.add(crf_layer) print(&apos;crf_layer.input_shape:&apos;, crf_layer.input_shape) print(&apos;crf_layer.output_shape:&apos;, crf_layer.output_shape) #pdb.set_trace() model.compile(loss=&apos;sparse_categorical_crossentropy&apos;, optimizer=&apos;sgd&apos;) BiLSTM是一个时序序列，添加层的参数设置中return_sequence值应为Fasle，若设置为True则每个时间步都会有一个输出值返回，设为False只会返回序列中最后一个时间步的输出值。其次在BiLSTM后接的CRF层也是时许序列，对应着的输出也是每个时间有输出，因此CRF的最终输出为（batch_size,timesteps,num_class）。而在本次任务中，只要求判断输入句子是否有语法错误，真值是一个shape为（batch_size,num_class）d的输出。还有time_layer = TimeDistributed(Dense(num_class))，其中TimeDistributed这个包装器将一个层应用于输入的每个时间切片，所以都是导致最后shape不符的原因，因此会出现上述错误。 解决方法：弃用CRF层和TimeDistributed层。发现不报错了……但目前还不知道怎么能让CRF和TimeDistributed层存在的情况下不报错，后续有了解决方法会有更新。 代码参考：用keras搭建bilstm crf]]></content>
      <categories>
        <category>Keras</category>
        <category>CodingErrors</category>
      </categories>
      <tags>
        <tag>Keras</tag>
        <tag>CodingErrors</tag>
        <tag>CRF</tag>
        <tag>BiLSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习之序列模型]]></title>
    <url>%2F2018%2F03%2F20%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[序列模型 —吴恩达深度学习第五课 Week 1循环序列模型1.1 为什么选择序列模型？ 在本次课程中会学习自行创建这些序列模型，先从一些使用了序列模型的例子来进行了解。 语音识别给出一段输入音频片段X,并要求输出片段对应的文字记录Y，在这个例子中输入数据和输出数据都是序列数据。因为X是一个按时序播放的音频片段，输出Y时一系列单词。所以之后将要学习到的一些序列模型，如循环神经网络等对于语音识别方面都是比较有用。 音乐生成问题也是序列模型的一个例子。而且只有输出数据是序列数据，它的输入数据可以是空集，也可以是个单一的整数，这个数可能指代你想要生成的音乐风格也可能是你想要生成的曲子的头几个音符. 情感分类输入数据是序列，例如“There is nothing to like in this movie.”,这句评论应为几星？—&gt; * DNA序列分析DNA序列可以用A G C T来表示，当给出一段DNA序列：AGCCCCTGTGAGGAACTAG，你能够标记出（AGCCCCTGTGAGGAACTAG）哪部分是匹配哪种蛋白质。 机器翻译输入：Voulez-vous chanter avecmoi? 输出：Do you want to sing with me? 视频行为识别输入：一系列的视频帧 输出：识别视频帧中的行为 命名实体识别给定一个句子，要求你识别出句子中的人名。所有这些问题都可以可以称为：使用标签数据（X,Y）作为训练集的监督学习。但是从这些例子中也可以看出序列问题有很多不同类型，有些问题里输入数据和输出数据都是序列，即使是在这种情况下X和Y有时也会不一样长，但是在例子4和例子7中是一样长的。在另一些问题里，只有X或是只有Y是序列。通过本课程会学到一些使用不同情况的序列模型。 1.2 数学符号 （Notation）定义序列学习符号，以便于一步步构建序列模型。 Motivating Example 当想要一个能够自动识别句中人名位置的序列模型时（显然是一个命名实体识别问题），这常用于搜索引擎，比如想要搜取过去24小时内所有新闻报道提及的人名，用这个方法就能够恰当的进行索引，命名实体识别系统可以用来查找不同类型文件中的人名、公司名、时间、地点、国家名等信息。给定了一个输入语句x，假如想要一个序列模型输出y,是的输入的每个单词都对应一个输出值，同时y又能够表明单词是否是人名的一部分，如果是人名则输出1，否则输出0。 输入语句x: Harry Potter and Hermione Granger invented a new spell . x1 x2 x3 x4 x5 x6 x7 x8 x9 (上标尖括号) 输出y: 1 1 0 1 1 0 0 0 0 y1 y2 y3 y4 y5 y6 y7 y8 y9 (上标尖括号) 上面这种输出方式也许并不是最好的，还有其它的复杂输出方式，不仅能够知道这个输入词是否是人名的一部分，还能知道这个人名在这个句子里从哪里开始到哪里结束。但是在上述这个例子中会讨论这种简单的输出方式。上述例子中的输入数据是有9个单词组成的序列，所以最后会有9个特征集合来表示这9个单词，并按序列中的位置（x^1）进行索引。用x^t来表示这个序列的中间位置，t表示这是一个时序序列，但不论是否是时许序列在这里都用t来表示索引序列中的位置，输出数据也一样。 y^t:表示输出数据 T_x：表示输入序列的长度 T_y：表示输出序列的长度，在本例中T_x = T_y = 9，但是在有些问题中两者的值也会不一样。 x^(i)尖括号t：表示第i个训练样本的第t个元素 T_x^(i)：表示的第i个训练样本的输入序列长度 一件需要我们事先决定的是：应该怎样表示句子中的一个单词？例如Harry这样的单词。而x^1究竟是什么。想要表示一个句子里的单词第一件事是做一张词表，[a,aaron,…,and,…,Harry,…Potter,…zulu],词表以列的的形式存在。构建这么一个词表的方法是：遍历你的训练集，然后查找到前10000个常用的单词，可以去浏览一些网络词典获得英语中常用的前10000个单词。接下来可以用one-hot表示法来表示词典里的每个单词，例如x^1表示Harry（在词典中位于第4075个位置）这个单词，那么就是一个第4075行是1其余位置都是0的列向量。用这种方式表示X的目的是,用序列模型在X和目标输出Y之间，学习建立一个映射。还剩最后一件事：如果遇到的单词不在词表中时，创建一个新的标记，也就是一个叫做Unknown Word的伪造单词，用“UNK”作为标记来表示不在词表中的单词。 1.3 循环神经网络模型如何建立一个模型/神经网络来学习X到Y的映射。可以尝试的方法之一是：使用标准的神经网络。 把上述例子中9个单词输入到一个标准的神经网络中，经过一些隐藏层后会输出9个值为0或1的项，它表明9个输入单词是否是人名的一部分。但是结果表明这种方法并不好，主要有两个问题： 输入输出数据在不同的样本中的长度不一样 在文本的不同位置上学到的特征并不共享（单词和单词之间的特性无法被捕捉到）。 比如神经网络在x^1的位置上发现harry是人名的一部分，在其他位置发现harry时你也希望也能识别出是人名出来。在卷积网络中我们是这样学习的，最大单词数乘以10000维的维度，那么在第一层的权重矩阵中会有巨量的参数。假设我们有10000个常用词，为其构建一个10000*1 的矩阵(column matrix)，假如第一个词是苹果(apple), 那么对应的第一个位置为1，其他都为0，所以称之为one-hot。这样每个单词都有对应的矩阵进行表示，如果这个词没有出现在我们的字典中，那么我们可以给一个特殊的符号代替，常用的是 [UNK] (unknown) 但是在下面要讲的循环神经网络却没有上述两种问题，那么什么是循环神经网络？如果从左到右读句子第一个单词假如说是x[^1]，将第一个单词输入到神经网络中的隐藏层，尝试预测输出y（判断是否是人名的一部分），那么循环神经网络做了些什么？当我们输入第二个单词时，同样通过隐层输出y，它不仅仅是利用了第二个单词的信息，它还利用了时间步1的信息，具体而言就是时间步1的激活值就会传递到时间步子2.在下一个时间步，在第三个单词输出y，直到最后一个时间布输入了x[^Tx]，输出y[^Ty]。在这个例子中Tx = Ty,但是如果Tx和Ty不同上面的神经网络结构也会有变化。所以在每一个时间步，循环神经网络传递一个激活值a到下一个时间布中用于计算。为了开始整个流程，在时间步0处设置一个激活值a^0,通常是一个零向量（伪激活值0最常见），也可以随即用其他方法初始化a^0。还有一种循环神经网络结构，为了表示循环画一个圈表示输回网络层，在这个圈上有一个黑色方块表示会延迟一个时间步。 用W_ax表示管理着从x^1到隐藏层的连接的一系列参数，每个时间步使用的都是相同的参数W_ax，而激活值是水平联系，是由参数W_aa决定的，同时每一个时间步使用的都是相同的参数W_aa,每一个时间步的输出由W_ya决定。 循环神经网络是从左向右扫描数据，同时每个时间步是共享参数的，共享参数，但有一个缺点是它只使用了当前位置在序列中之前的输入信息来预测并没有使用序列中后部分的信息。而双向循环神经网络解决了这个问题，它同时使用前面和后面的信息。 那么这些参数是如何起作用的？上图是一张清理后的神经网络图示，一开始先输入a^0(是个零向量)，接下来就是前向传播过程,为了算出a(1):a(1)=g(W_aaa^(0)+W_axx^(1)+B_a) –&gt;循环神经网络常用激活函数：tanh/Reluy(1)=g(W_ya*a^(1)+B_y) –&gt;根据输出选择sigmooid/softmax (矩阵下标的符号说明：W_ax，第二个下标意味着W_ax要乘以某个x类型的量，a是表明要计算的某个a类型的量) 更常用:a(t)=g(W_aaa^(t-1)+W_ax(x^t)+B_a)y(t)=g(W_yaa^(t)+b_y)简化上面两个等式：a(t)=g(W_a[a^(t-1),x^(t)]+B_a)定义W_a = [W_aa|W_ax],假设W_aa是一个（100，100）维的矩阵，那么W_ax是(100,10000),W_a是(100,10100)[a^(t-1),x^(t)]的意思是将这两个向量行堆在一起，形成了一个10100维度的向量。这样做的好处是把参数矩阵压缩成一个W_a,当建立更加复杂的模型时可以简化符号。同样地，y^t = g(W_ya^(t) + B_y),W_y和B_y仅有一个下标表明输出什么类型的量。 1.4 通过时间的反向传播损失函数,定义为标准的logistic回归损失函数，也称为交叉熵损失函数。在这个反向传播过程中，最重要的信息传递或者说最重要的递归运算就是从右到左的运算，这种运算有一个别致的名字：通过时间（“穿越时间”）反向传播。 1.5不同类型的循环神经网络在前面几节已经了解了T_x和T_y相等情况下的循环神经网络。但是T_x和T_y并不总是相等的。 Examples Music generation:T_x长度可以是0（空集）或1，one-to-many形式，就是一个序列生成问题。 文本情感分类：输出y可以是1到5的，而输入是一个序列我们在RNN结构中读入所有单词后再输出y’(预测值，一个数字)，many-to-one 机器翻译：many-to-many，输入输出的长度不同。 对于Many to many 结构有两种： T_x和T_y相等。 T_x和T_y不相等。 1.6语言模型与序列生成(Language model and sequence generation)什么是语言模型呢？ 语音识别系统 the apple and pair salad. the apple and pear salad. p(the apple and pair salad)=3.2*10^(-13) p(the apple and pear salad)=3.2*10^(-10)语言模型所做的就是：一个句子出现的概率是多少？p(sentences)= ?语言模型所的基础工作：输入一个句子（准确的说是一个文本序列y^1,…,y^(T_y)），语言模型会估计某个句子中各个单词出现的概率。So,如何来用RNN来建语言模型呢？首先需要一个训练集，包含一个很大的英文文本语料库或者其他的语料库。假如有一个句子：Cats average 15 hours of sleep a day.首先把这个句子标记化（tokenize），即像之前那样创建一个词典，把每个单词转换成对应的one-hot向量，也就是字典中的索引，另外增加一个’EOS’为句子的结束标记。EOS也可以做为训练集中每一个句子的结尾。如果训练集中有一些词不在词典中，unk标记这个单词。我们只针对UNK这个词来进行概率模型构建而不针对这个具体的词。完成标记化的过程后表示将这个句子都映射到了各个标志上或者说字典中的各个词上。接下来我们会构建一个RNN模型来构建这些序列的概率模型。 构建RNN模型（把x^t设为y^(t-1)）Cats average 15 hours of sleep a day.《EOS》在第0个时间不，计算激活项a^1,它是以x^1作为输入的函数，在这里x^1是被设为零向量的，在之前的a^0，按照惯例也是被设为零向量的，于是a^1要做的是它会通过softmax进行一些预测来计算出第一个词，其结果就是y’^1。这一步其实是通过一个soft max层来预测字典中的任意一个单词会是第一个词的概率。 所以y’^1只是来预测第一个词的概率，而不必管结果是什么。所有当字典中有10000个词时通过softmax就会有10000种结果（或包括UNK和EOS两种在内的10002中）。然后RNN进入下个时间步，仍然使用激活项a^1,然后在这一步要做出的计算是第二个词会是什么，现在我们依然传给它正确的第一个词y^1（cats），其实也就是x^2，使用激活项a^2，通过softmax层得到y’^2,也就是p(average/cats)为多少，然后依照之前传入下一时间步。然后最后会传递到如上图所示第九个时间步，然后把x^9也就是y^8=”day”传递给它，得到y’^9(“EOS”)。看图理解！ 接下来为了用RNN来训练这个网络，我们要定义代价函数： 或者也可以理解为：预测每个词的概率是多少，y是一个10000+2维（字典大小+unk+结束标记）。现在有一个新的序列 y1,y2,y3.现在要计算出整个句子各个单词的出现概率P(y^1,y^2,y^3) = p(y^1)p(y^2|y^1)p(y^3|y^1,y^2),第一个softmax层告诉你p(y1)第二个softmax,p(y2|y1),第三个p(y3|y1,y2)。 接下来讨论如何用语言模型从模型中采样。 1.7 对新序列采样当你训练了一个模型后，要想了解这个模型学到了什么，一个非正式的方法是进行一次新序列采样。记住，一个序列模型，模拟了任意特定单词序列的概率，我们要做的是对这个概率分布进行采样，来生成一个新的单词序列。 这个网络已经被下图中的所示结构训练过了， 而为了进行采样要做一些截然不同的事情。比如说现在有一个训练好的模型，为了进行采样，第一步要做的事就是，对你想要模型生成的第一个词进行采样，于是输入x^1=0,a^1=0,而第一个时间步得到的是所有可能的输出，是经过softmax层后得到的概率，然后 根据这个softmax的分布进行随机取样。softmax给你的就是第一个单词是a的概率是多少，是aaron的概率是多少，…是zulu或是unk的概率是多少， 然后对这个向量使用例如np.random.choice来根据向量中这些概率的分布进行采样，这样就能对第一个词进行采样了。然后继续下一个时间步，记住，第二个时间步需要y^1作为输入，而现在要做的是把刚刚进行采样的词y’^1当作下一时间步的输入x^2，无论在上一个时间步得到的是什么词都要把他传递到下一个位置作为输入，(x2=y’^1),然后softmax就会预测得到y’^2。比如，你在第一个时间步得到的是the, 然后把它作为x^2，同样依次进行。不管得到什么都把它传递下去知道最后一个时间步。 怎么判断这个句子结束？方法就是，如果代表句子结尾的EOS标记在你的字典中，你可以一直进行采样直到得到EOS标记，这代表着你已经抵达结尾，可以停止采样了。另外一种情况是，如果字典中没有这个词，你可以决定从20个或100个或其他个词中进行采样 ，然后一直将抽样进行下去，直到达到所设定的时间步。不过这种过程会产生一些未知标记，如果你要确保你的算法不会输出这种标识，就要拒绝采样过程中产生任何未知的标记，一旦出现就继续在剩下的词中重新进行采样，直到得到一个不是未知标识的词，不介意未知标识产生的话你也可以不管。以上就是如何从一个RNN语言模型生成一个随机选择的句子。直到现在我们所建立的是基于词汇的RNN模型，意思就是字典中的词都是英语单词。根据实际应用也可以构建一个基于字符的RNN结构，字典中仅包含从a到z的字母，也可以有空格符、数字0到9，大写字幕A到Z，[a，b，c，..z， ，。，,，;，0，…，9，A，…，Z]，可以看一看实际的训练集中可能会出现的字符，一起来构建一个字典。相较于基于词汇的模型，基于字符模型的y^1,y^2等都是单独的字符而不是单独的词汇。基于字符的语言模型，不会产生unk标志，一得到很多、很长的序列，基于字符的语言模型，在捕捉句子中也只是捕捉句子较前部分如何影响较后部分，不如基于词汇的模型能够捕捉长范围的信息。 1.8 带有神经网络的梯度消失（Vanishing gradients with RNNs）以一个语言模型为例子，有一句话如下： The cat which already ate and maybe already ate a bunch of food that was delicious … was full.其中cat是单数所以是“was full”。 The cats which already ate …,were full. cats对应的是”were full”。 这个句子中的信息有长期的依赖，最前面的单词对后面的单词有影响。但是目前我们所见到的RNN语言模型结构，不擅长捕捉这种长期依赖效应。之前讨论过训练很深的网络会有梯度消失的问题。比如说有一个很深很深的网络，对这个网络从左到右做前向传播然后再反向传播， 我们知道如果是个很深的网络难么得到的y’很难传播回去，很难影响到靠前面的权重，很难影响前面层的计算。对于有同样问题的RNN，很难让一个很深的网络层能够意识到要记住前面的信息然后告诉后面的序列信息生成依赖效应从而选择是用was 还是were。基本的RNN模型有很多限制，很难调整序列前面的计算。如果不解决的话RNN会不擅长这种长期依赖问题。在反向传播时，随着层数的增多，梯度不仅可能指数型的下降，还会出现指数级的上升（梯度爆炸问题）。事实上，梯度下降在训练RNN时是首要的问题，尽管梯度爆炸也会出现，但是梯度爆炸很明显，因为指数级大的梯度会让参数变得很大，以至于网络参数崩溃，所以梯度爆炸很容易发现，会看到很多NaN或者不是数字的情况，这意味着你的网络计算出现了数值溢出。如果发现了梯度爆炸的问题，一个解决方法就是用梯度修剪，即观察梯度向量如果它大于某个阈值，缩放梯度向量保证它不会太大， 这就是通过一些最大值来修剪的方法。梯度消失更难解决。 1.9 GRU（Gated Recurrent Unit，门控循环单元）GRU改变了RNN的隐藏层，使其更好的捕捉深层连接(捕捉长范围的依赖)并改善了梯度消失的问题。上图（是RNN隐藏层的单元的可视化呈现）中的公式是指：在一个RNN结构的时间序列t处计算激活值， 把RNN的单元画个图，输入a^(t-1),即上一个时间步的激活值，然后在输入一个x^t，把它们两个合并起来，然后加上权重项，经过计算后，假设g是tanh函数，经过tanh得到激活值a^t，然后这个激活值会传递给一个softmax单元或者其它用于产生输出y’^t的东西。 许多GRU的想法来自于两篇paper。上图中给出的句子，如下： the cat which already ate ...,was full. 当我们从左到右读这个句子，GRU会有一个新的变量c代表记忆细胞（memory cell），当它看到一只猫是单数还是复数之再看到后面的句子后仍能够判断句子的主语究竟是单数还是复数。于是在时间t处，记忆细胞有关于t的值c。然而实际上GRU输出了激活值a^t，c^t = a^t。于是我们使用不同的符号c和a来表示记忆细胞的值和输出的激活值，即使他们是一样的。（注意：在LSTM中这两个值是不一样的。）在每一个时间步，我们将用一个候选值(即c~^t的值,就是个替代值)重写记忆细胞，候选值替代了c^t的值，然后用tanh函数来计算这个候选值。公式如下 c~^t=tanh(W_c[c^(t-1),x^t]+b_c) --用c~更新c的等式 然而GRU中最重要的思想是： 我们有一个门（gate）,把这个门叫做Γ_u ，其中Γ是大写的希腊字母读作gamma，u是下标，代表更新门（update gate），这是一个0到1之间的值。 Γ_u=sigmoid(W_u[c^(t-1),x^t]+b_u) --用F_u更新门决定是否要真的更新 于是我们可以这么看待,记忆细胞c将被设定为0或1，这取决于你考虑的单词在句子中是单数还是复数，然后GRU单元会一直记住c^t的值（假设为1），一直到（”was”）处还是1，所以用was。于是gate的作用就是决定什么时候你会更新这个值，特别是当你看到词组 the cat（句子的主语）时，你会知道在说一个新的概念，这就是一个好时机去更新，然后当你使用它的时候，就不需要记住它了（这个地方我有疑问）。So，接下来要给GRU用的式子是： c^t = Γ_u * c~^t + (1-Γ_u)*c^(t-1) 注意到，如果更新值Γ_u是1，也就是说把这个新值c^t设为候选值，然后相同的将门值设为1，然后往前，再更新这个值，对于所有在这直接按的值应该把门的值设为0（不更新用旧的值）。 因为gate很容易取到0，只要（W_u[c^(t-1),x^t]+b_u）这个值是一个很大的负数，就基本为0，这样有利于维持细胞的值，因为gamma很接近0，可能是0.0000001或者更小，这样就不会有梯度消失的问题，这就是说c^t基本等于c^(t-1),而c^t的值也很好的被维持了，即使经过很多的时间步还是可以很好的维持下来，这就是缓解梯度消失的关键。一些实现细节：c^t可以是向量，假如有一个100维的隐藏的激活值，那么c^t也是100维的，c~^t、Γ_u也是相同的维度。 完整的GRU对于full GRU要做的一个改变就是：在第一个式子中给记忆细胞的新候选值，加上一个新的项Γ_r，您可以认为r代表相关性，Γ_r（相关门）用来计算出下一个c^t的候选值和c^(t-1)的相关性程度。 Γ_r=sigmoid(W_r[c^(t-1),x^t]+b_r) 1.10 长短期记忆（Long Short Term Memory,LSTM）比GRU更有效、更广泛应用。 注意到，在LSTM中不再有a^t=c^t的情况，一个LSTM的新特性是不只有一个更新门Γ_u控制，还有一个遗忘门Γ_f，一个新的输出门Γ_o， 于是更新值 c^t = Γ_u*c~^t + Γ_f*c^(t-1) 所以这给了记忆细胞选择权去维持旧的值c^(t-1)或者就加上新的值c~^t，这时 a^t = Γ_o*c^t 。下图中就是控制LSTM的几个公式： 选择使用GRU或LSTM并没有统一的准则。GRU的结构更简单，更容易去构建一个更大的网络，它只有两个门在计算性上也运行的更快，扩大模型的规模。但是LSTM有三个门，更加强大和灵活。 1.11 双向神经网络（Bidirectional RNN，BRNN）以上已经了解过RNN模型的关键的结构，还有两种方法能构建更好的模型，其中之一就是双向RNN模型，这个模型不仅可以让你在序列的某点处获取之前的信息还可以获取未来的信息；第二个就是深层的RNN。 为了了解双向RNN的动机，我们先看下命名实体识别那个例子上图所示。Teddy判断是不是人名有个问题，只看前几个单词是无法准确判断的，双向RNN可以解决这个问题。下图解释双向RNN的工作原理。 给定一个输入序列，这个网络的前向先计算a^1，a^2,…,a^(T_x)，然后反向的序列计算a^(T_x),…,a^2,a^1，这两个方向的计算都是前向传播，一个是从左到右的前向计算，一个是从右到左的反向计算。把这些反向的网络激活值都算完了就可以计算预测结果了。 事实上，很多的NLP问题对于大量有自然语言处理问题的文本，有LSTM单元的双向RNN模型是用的最多的，所以如果有NLP问题，并且文本句子都是完整的，首先需要标定这些句子，一个有LSTM单元的双向RNN模型有前向和反向传播过程是个不错的首选。 1.12 深度RNN有的时候为了得到更好的模型，需要把很多个RNN堆叠加在一起，这种网络我们称之为深层RNN。用a^([1]0)表示原来的激活值a^0。a^([l]t)：l表示第l层，t表示第t个时间点。比如我们要计算 a^（[2]3），它有两个输入。 a^([2]3)=g((W_a)^[2] [a^([2]2),a^([1]3]+(b_a)^[3])]]></content>
      <categories>
        <category>DeepLearning</category>
        <category>RNN</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>Neural Network</tag>
        <tag>RNN</tag>
        <tag>LSTM</tag>
        <tag>GRU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之Logging]]></title>
    <url>%2F2018%2F03%2F20%2FPython%E4%B9%8BLogging%2F</url>
    <content type="text"><![CDATA[Python | logging??(?https://www.cnblogs.com/liujiacai/p/7804848.html)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>logging</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python | 正则表达式]]></title>
    <url>%2F2018%2F03%2F20%2FPython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Python | 正则表达式 正则表达式修饰符 - 可选标志正则表达式可以包含一些可选标志修饰符来控制匹配的模式。修饰符被指定为一个可选的标志。多个标志可以通过按位 OR(|) 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志： 正则表达式小知识**总结** ^ 匹配字符串的开始 $ 匹配字符串的结尾 \b 匹配一个单词的边界。 \d 匹配任意数字。 \D 匹配任意非数字字符。 p? 匹配一个可选的 p 字符 (换言之，它匹配 1 次或者 0 次 p 字符)。 p* 匹配0次或者多次 p 字符。 p+ 匹配1次或者多次 p 字符。 p{n,m} 匹配 p 字符，至少 n 次，至多 m 次。 (a|b|c) 要么匹配 a，要么匹配 b，要么匹配 c。 (p) 一般情况下表示一个记忆组 (remembered group)。你可以利用 re.search 函数返回对象的 groups() 函数获取它的值。 . 正则表达式中的点号通常意味着 “匹配任意单字符” ###匹配标签对:http://blog.csdn.net/eastmount/article/details/51082253 ###正则总结转自：http://blog.csdn.net/u014052851/article/details/76640149]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
        <tag>标签对处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras之序贯模型快速开始]]></title>
    <url>%2F2018%2F03%2F20%2FKeras%E5%BA%8F%E8%B4%AF%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[Keras序贯模型快速开始re: 官方-中文文档序贯模型是多个网络层的线性堆叠。可以通过向Sequential模型传递一个layer的list来构造该模型： “&apos;Python from keras.models import Sequential from keras.layers import Dense,Activation model = Sequential([ Dense(32,units=784),Activation(&apos;relu&apos;),Dense(10),Activation(&apos;softmax&apos;), ]) 也可以通过.add()方法一个个的添加layer到模型中 “&apos;Python model = Sequential() model.add(Dense(32,input_shape=(784,)) model.add(Actiovation(&apos;relu&apos;)) 指定输入数据的shape模型需要知道输入数据的shape，因此Sequential的第一层需要接受一个关于输入数据shape的参数，后面各个层则可以自动的推导出中间数据的shape，因此不需要为每个层都指定这个参数。有几种方法来为第一层指定输入数据的shape： 传递一个input_shape的关键字参数给第一层，input_shape是一个tuple类型的数据，其中也可以填入None，如果填入None则表示此位置可能是任何正整数。数据的batch大小不应包含在其中。 有些2D层 ，如Dense,支持通过指定其输入维度input_dim来隐含的指定输入数据shape,是一个Int类型的数据。一些3D的时域层支持通过参数input_dim和input_length来指定输入shape。 “&apos;Python model = Sequential() model.add(Dense(32, input_dim=784)) 如果你需要为输入指定一个固定大小的batch_size（常用于stateful RNN网络），可以传递batch_size参数到一个层中，例如你想指定输入张量的batch大小是32，数据shape是（6，8），则你需要传递batch_size=32和input_shape=(6,8)。 “&apos;Python model = Sequential() model.add(Dense(32, input_shape=(784,))) 编译在训练模型之前，我们需要通过compile来对学习过程进行配置。compile接收三个参数： “&apos;Python # For a multi-class classification problem model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;]) # For a binary classification problem model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;binary_crossentropy&apos;, metrics=[&apos;accuracy&apos;]) # For a mean squared error regression problem model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;mse&apos;) # For custom metrics import keras.backend as K def mean_pred(y_true, y_pred): return K.mean(y_pred) model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;binary_crossentropy&apos;, metrics=[&apos;accuracy&apos;, mean_pred]) 训练Keras以Numpy数组作为输入数据和标签的数据类型。训练模型一般使用fit函数，该函数的详情见这里。下面是一些例子。 “&apos;Python # For a single-input model with 2 classes (binary classification): model = Sequential() model.add(Dense(32, activation=&apos;relu&apos;, input_dim=100)) model.add(Dense(1, activation=&apos;sigmoid&apos;)) model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;binary_crossentropy&apos;, metrics=[&apos;accuracy&apos;]) # Generate dummy data import numpy as np data = np.random.random((1000, 100)) labels = np.random.randint(2, size=(1000, 1)) # Train the model, iterating on the data in batches of 32 samples model.fit(data, labels, epochs=10, batch_size=32) 第二个例子 : “` # For a single-input model with 10 classes (categorical classification): model = Sequential() model.add(Dense(32, activation=&apos;relu&apos;, input_dim=100)) model.add(Dense(10, activation=&apos;softmax&apos;)) model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;]) # Generate dummy data import numpy as np data = np.random.random((1000, 100)) labels = np.random.randint(10, size=(1000, 1)) # Convert labels to categorical one-hot encoding one_hot_labels = keras.utils.to_categorical(labels, num_classes=10) # Train the model, iterating on the data in batches of 32 samples model.fit(data, one_hot_labels, epochs=10, batch_size=32)]]></content>
      <categories>
        <category>Keras</category>
      </categories>
      <tags>
        <tag>Keras</tag>
        <tag>序贯模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[blogsPictures]]></title>
    <url>%2F2018%2F02%2F02%2FblogsPictures%2F</url>
    <content type="text"><![CDATA[Python: https://i.loli.net/2019/04/04/5ca5cc3c2711d.jpg Deeplearning: https://i.loli.net/2019/04/04/5ca5d07c0260b.jpg Keras: https://i.loli.net/2019/04/04/5ca5d1a7aa93c.jpg NLP: https://i.loli.net/2019/04/04/5ca5d4fb76e7d.jpg Papers: https://i.loli.net/2019/04/04/5ca5d524ec8fa.jpg Pytorch: https://i.loli.net/2019/04/04/5ca5d59e9c49d.jpg Sparetime: https://i.loli.net/2019/04/04/5ca5ce4b6ff50.jpg 学习计划: https://i.loli.net/2019/04/04/5ca5d56ab6a94.jpg]]></content>
      <categories>
        <category>SpareTime</category>
      </categories>
      <tags>
        <tag>SpareTime</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HelloBlog]]></title>
    <url>%2F2018%2F02%2F02%2FHelloBlog%2F</url>
    <content type="text"><![CDATA[怕什么真理无穷,进一寸有一寸的欢喜 next主题NexT 主题优化个性化配置教程]]></content>
      <categories>
        <category>SpareTime</category>
      </categories>
      <tags>
        <tag>SpareTime</tag>
      </tags>
  </entry>
</search>
